import os
import joblib
import tensorflow as tf

# Variable globale pour √©viter de recharger les mod√®les plusieurs fois
_cached_models = None

def load_models(model_dir):
    """Charge les mod√®les d'imputation et de d√©tection UNE SEULE FOIS."""
    global _cached_models
    if _cached_models is not None:
        return _cached_models  # Retourner directement si les mod√®les sont d√©j√† en m√©moire

    models = {}
    if not os.path.exists(model_dir):
        print(f"‚ùå Le r√©pertoire des mod√®les {model_dir} n'existe pas.")
        return models

    for model_file in os.listdir(model_dir):
        model_path = os.path.join(model_dir, model_file)

        if model_file.endswith('.pkl'):
            col_name = model_file.replace('.pkl', '')
            try:
                models[col_name] = joblib.load(model_path)
                print(f"‚úÖ Mod√®le charg√© : {col_name}")
            except Exception as e:
                print(f"‚ùå Erreur lors du chargement du mod√®le {model_file}: {e}")

    # üîπ Charger le mod√®le SAE
    sae_path = os.path.join(model_dir, "sae_trained.keras")
    if os.path.exists(sae_path):
        try:
            models["sae"] = tf.keras.models.load_model(sae_path)
            print("‚úÖ Mod√®le SAE charg√© avec succ√®s !")
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du mod√®le SAE : {e}")

    # üîπ Charger le Scaler
    scaler_path = os.path.join(model_dir, "scaler.pkl")
    if os.path.exists(scaler_path):
        try:
            models["scaler"] = joblib.load(scaler_path)
            print("‚úÖ Scaler charg√© avec succ√®s !")
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du Scaler : {e}")

    # üîπ Charger le seuil d'anomalie
    threshold_path = os.path.join(model_dir, "threshold_final.pkl")
    if os.path.exists(threshold_path):
        try:
            models["threshold"] = joblib.load(threshold_path)
            print(f"‚úÖ Seuil d'anomalie charg√© : {models['threshold']}")
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du Seuil d'anomalie : {e}")

    _cached_models = models  # Stocker les mod√®les en cache
    print(f"‚úÖ {len(models)} mod√®les charg√©s avec succ√®s.")
    return models
