import os
import joblib
import tensorflow as tf
import logging
import subprocess

# Configuration du logger
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)

# Variable globale pour √©viter de recharger les mod√®les plusieurs fois
_cached_models = None


def load_models(model_dir):
    """
    Charge les mod√®les d'imputation et de d√©tection UNE SEULE FOIS.
    V√©rifie si les mod√®les existent et tente de les r√©cup√©rer avec DVC si absents.

    :param model_dir: Chemin vers le r√©pertoire des mod√®les.
    :return: Dictionnaire contenant les mod√®les charg√©s.
    """
    global _cached_models
    if _cached_models is not None:
        return _cached_models  # Retourne les mod√®les en cache s'ils sont d√©j√† charg√©s

    models = {}

    # üìå V√©rifier si le dossier des mod√®les existe et contient des fichiers
    if not os.path.exists(model_dir) or not os.listdir(model_dir):
        logging.warning("üì• Mod√®les absents. Tentative de r√©cup√©ration via DVC...")
        try:
            subprocess.run(["dvc", "pull"], check=True)
            logging.info("‚úÖ Mod√®les r√©cup√©r√©s avec succ√®s via DVC !")
        except subprocess.CalledProcessError:
            logging.error("‚ùå √âchec de la r√©cup√©ration des mod√®les avec DVC.")
            return models  # On retourne un dictionnaire vide si l‚Äôop√©ration √©choue

    model_files = os.listdir(model_dir)
    if not model_files:
        logging.warning(f"‚ö†Ô∏è Aucun fichier mod√®le trouv√© dans {model_dir}.")
        return models

    # üîπ Chargement des mod√®les `.pkl`
    for model_file in model_files:
        model_path = os.path.join(model_dir, model_file)

        if model_file.endswith(".pkl"):
            col_name = model_file.replace(".pkl", "")
            try:
                models[col_name] = joblib.load(model_path)
                logging.info(f"‚úÖ Mod√®le charg√© : {col_name}")
            except Exception as e:
                logging.error(f"‚ùå Erreur lors du chargement du mod√®le {model_file}: {e}")

    # üîπ Chargement du mod√®le SAE (`sae_trained.keras`)
    sae_path = os.path.join(model_dir, "sae_trained.keras")
    if os.path.exists(sae_path):
        try:
            models["sae"] = tf.keras.models.load_model(sae_path)
            logging.info("‚úÖ Mod√®le SAE charg√© avec succ√®s !")
        except Exception as e:
            logging.error(f"‚ùå Erreur lors du chargement du mod√®le SAE : {e}")

    # üîπ Chargement du scaler (`scaler.pkl`)
    scaler_path = os.path.join(model_dir, "scaler.pkl")
    if os.path.exists(scaler_path):
        try:
            models["scaler"] = joblib.load(scaler_path)
            logging.info("‚úÖ Scaler charg√© avec succ√®s !")
        except Exception as e:
            logging.error(f"‚ùå Erreur lors du chargement du Scaler : {e}")

    # üîπ Chargement du seuil d'anomalie (`threshold_final.pkl`)
    threshold_path = os.path.join(model_dir, "threshold_final.pkl")
    if os.path.exists(threshold_path):
        try:
            models["threshold"] = joblib.load(threshold_path)
            logging.info(f"‚úÖ Seuil d'anomalie charg√© : {models['threshold']}")
        except Exception as e:
            logging.error(f"‚ùå Erreur lors du chargement du Seuil d'anomalie : {e}")

    _cached_models = models  # Stocke les mod√®les en cache pour √©viter de les recharger plusieurs fois

    logging.info(f"üìå {len(models)} mod√®les charg√©s avec succ√®s.")
    return models
