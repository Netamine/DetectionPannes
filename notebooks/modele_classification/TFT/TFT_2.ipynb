{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b54d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "##                  TFT                  ##\n",
    "###########################################\n",
    "## Chargement des donn√©es\n",
    "## Conversion des types\n",
    "## S√©paration Train / Test\n",
    "## Pr√©paration des TimeSeriesDataSet\n",
    "## D√©finition des DataLoaders\n",
    "## Initialisation du mod√®le TFT\n",
    "## Entra√Ænement du mod√®le\n",
    "## Sauvegarde et chargement du mod√®le\n",
    "## Pr√©diction et affichage des r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a0a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "# Charger le dataset\n",
    "df = pd.read_csv(r\"..\\..\\..\\..\\Datasources\\MetroPT3_new_imputed_final.csv\", delimiter=\",\", decimal=\".\", index_col=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac12a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset commence le 2020-04-12 11:20:00 et se termine le 2020-07-17 06:00:00\n",
    "pannes = [\n",
    "    {'id': 'Panne1',  'start': '2020-04-12 11:50:00', 'end': '2020-04-12 23:30:00'},\n",
    "    {'id': 'Panne2',  'start': '2020-04-18 00:00:00', 'end': '2020-04-18 23:59:00'},\n",
    "    {'id': 'Panne3',  'start': '2020-04-19 00:00:00', 'end': '2020-04-19 01:30:00'},\n",
    "    {'id': 'Panne4',  'start': '2020-04-29 03:20:00', 'end': '2020-04-29 04:00:00'},\n",
    "    {'id': 'Panne5',  'start': '2020-04-29 22:00:00', 'end': '2020-04-29 22:20:00'},\n",
    "    {'id': 'Panne6',  'start': '2020-05-13 14:00:00', 'end': '2020-05-13 23:59:00'},\n",
    "    {'id': 'Panne7',  'start': '2020-05-18 05:00:00', 'end': '2020-05-18 05:30:00'},\n",
    "    {'id': 'Panne8',  'start': '2020-05-19 10:10:00', 'end': '2020-05-19 11:00:00'},\n",
    "    {'id': 'Panne9',  'start': '2020-05-19 22:10:00', 'end': '2020-05-19 23:59:00'},\n",
    "    {'id': 'Panne10', 'start': '2020-05-20 00:00:00', 'end': '2020-05-20 20:00:00'},\n",
    "    {'id': 'Panne11', 'start': '2020-05-23 09:50:00', 'end': '2020-05-23 10:10:00'},\n",
    "    {'id': 'Panne12', 'start': '2020-05-29 23:30:00', 'end': '2020-05-29 23:59:00'},\n",
    "    {'id': 'Panne13', 'start': '2020-05-30 00:00:00', 'end': '2020-05-30 06:00:00'},\n",
    "    {'id': 'Panne14', 'start': '2020-06-01 15:00:00', 'end': '2020-06-01 15:40:00'},\n",
    "    {'id': 'Panne15', 'start': '2020-06-03 10:00:00', 'end': '2020-06-03 11:00:00'},\n",
    "    {'id': 'Panne16', 'start': '2020-06-05 10:00:00', 'end': '2020-06-05 23:59:00'},\n",
    "    {'id': 'Panne17', 'start': '2020-06-06 00:00:00', 'end': '2020-06-06 23:59:00'},\n",
    "    {'id': 'Panne18', 'start': '2020-06-07 00:00:00', 'end': '2020-06-07 14:30:00'},\n",
    "    {'id': 'Panne19', 'start': '2020-07-08 17:30:00', 'end': '2020-07-08 19:00:00'},\n",
    "    {'id': 'Panne20', 'start': '2020-07-15 14:30:00', 'end': '2020-07-15 19:00:00'},\n",
    "    {'id': 'Panne21', 'start': '2020-07-17 04:30:00', 'end': '2020-07-17 05:30:00'}\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b852406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir timestamp en datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# D√©finir la date de s√©paration entre Train et Test\n",
    "split_date = \"2020-06-05 23:59:10\"  # S√©paration temporelle (Fin de la panne 16)\n",
    "\n",
    "# S√©parer les donn√©es en train/test\n",
    "df_train = df[df[\"timestamp\"] < split_date].copy()\n",
    "df_test = df[df[\"timestamp\"] >= split_date].copy()\n",
    "\n",
    "# Recalculer time_idx en divisant par 10 pour √©viter les grands nombres\n",
    "df_train[\"time_idx\"] = ((df_train[\"timestamp\"] - df_train[\"timestamp\"].min()).dt.total_seconds() // 10).astype(int)\n",
    "df_test[\"time_idx\"] = ((df_test[\"timestamp\"] - df_test[\"timestamp\"].min()).dt.total_seconds() // 10).astype(int)\n",
    "\n",
    "print(f\"Min time_idx in df_train: {df_train['time_idx'].min()}, Max: {df_train['time_idx'].max()}\")\n",
    "print(f\"Min time_idx in df_test: {df_test['time_idx'].min()}, Max: {df_test['time_idx'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff98fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir les colonnes cat√©goriques et les forcer en str avant de les convertir en category\n",
    "for col in [\"COMP\", \"DV_eletric\", \"Towers\"]:\n",
    "    df_train[col] = df_train[col].astype(int).astype(str).astype(\"category\")\n",
    "    df_test[col] = df_test[col].astype(int).astype(str).astype(\"category\")\n",
    "\n",
    "# Conversion explicite de panne\n",
    "df_train[\"panne\"] = df_train[\"panne\"].astype(int).astype(str).astype(\"category\")\n",
    "df_test[\"panne\"] = df_test[\"panne\"].astype(int).astype(str).astype(\"category\")\n",
    "\n",
    "print(\"Conversion des colonnes cat√©goriques et de panne termin√©e.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c2dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter un group_id unique pour tout le dataset\n",
    "df_train[\"group_id\"] = \"compresseur\"\n",
    "df_test[\"group_id\"]  = \"compresseur\"\n",
    "\n",
    "print(\"group_id ajout√©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0222e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir les encodeurs pour les variables cat√©goriques\n",
    "categorical_encoders = {\n",
    "    \"COMP\": NaNLabelEncoder(),\n",
    "    \"DV_eletric\": NaNLabelEncoder(),\n",
    "    \"Towers\": NaNLabelEncoder(),\n",
    "}\n",
    "\n",
    "print(\"Encodeurs cat√©goriques d√©finis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir l'horizon de pr√©vision et la fen√™tre d'observation\n",
    "max_encoder_length = 30  # Fen√™tre plus longue pour √©viter la suppression\n",
    "max_prediction_length = 3  # Une seule pr√©diction pour √©viter les erreurs\n",
    "\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    df_train,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"panne\",\n",
    "    group_ids=[\"group_id\"],  # Utiliser un ID unique par s√©rie\n",
    "    time_varying_known_reals=[\"TP2\", \"H1\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\"],\n",
    "    time_varying_known_categoricals=[\"DV_eletric\", \"Towers\"],\n",
    "    max_encoder_length=30,  \n",
    "    max_prediction_length=3,  \n",
    "    min_encoder_length=10,  # Augmenter pour √©viter des s√©quences trop courtes\n",
    "    min_prediction_length=3,\n",
    "    categorical_encoders=categorical_encoders,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Dataset train cr√©√© avec {len(train_dataset)} s√©quences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TimeSeriesDataSet(\n",
    "    df_test,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"panne\",\n",
    "    group_ids=[\"COMP\"],\n",
    "    time_varying_known_reals=[\"TP2\", \"H1\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\"],\n",
    "    time_varying_known_categoricals=[\"DV_eletric\", \"Towers\"],\n",
    "    max_encoder_length=10,  # Doit √™tre identique √† train_dataset\n",
    "    max_prediction_length=3,  # Doit √™tre identique √† train_dataset\n",
    "    min_encoder_length=5,\n",
    "    min_prediction_length=2,\n",
    "    categorical_encoders=categorical_encoders,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset test cr√©√© avec {len(test_dataset)} s√©quences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c478f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Nombre de groupes dans test_dataset: {len(test_dataset.index) if hasattr(test_dataset, 'index') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3498b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "# D√©finition du mod√®le TFT (Pas besoin de `LightningModule`)\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=1e-3,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# Pas besoin d'assertion sur `LightningModule`\n",
    "print(f\"Mod√®le TFT initialis√© avec {tft.size()} param√®tres.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecfe440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "# Cr√©ation du wrapper LightningModule\n",
    "class TFTLightningModule(LightningModule):\n",
    "    def __init__(self, tft):\n",
    "        super().__init__()\n",
    "        self.model = tft\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self.model(x)\n",
    "        loss = self.model.loss(y_pred, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        if batch is None or \"x\" not in batch or \"y\" not in batch:\n",
    "            print(f\"Batch {batch_idx} mal structur√© : {batch}\")\n",
    "            return None  # √âvite une erreur bloquante\n",
    "\n",
    "        x = batch[\"x\"]\n",
    "        y = batch[\"y\"]\n",
    "\n",
    "        try:\n",
    "            y_pred = self.model(x)\n",
    "            loss = self.model.loss(y_pred, y)\n",
    "        except KeyError as e:\n",
    "            print(f\"Erreur de cl√© dans `validation_step`: {e}\")\n",
    "            return None\n",
    "\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.model.configure_optimizers()\n",
    "\n",
    "# Encapsulation du mod√®le TFT dans `LightningModule`\n",
    "tft_lightning = TFTLightningModule(tft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22541e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def tft_collate_fn(batch):\n",
    "    \"\"\" Collate function pour le mod√®le TFT, en s'assurant que les tailles et types sont coh√©rents. \"\"\"\n",
    "    \n",
    "    # Filtrer les √©chantillons invalides (None)\n",
    "    batch = [b for b in batch if b is not None]  \n",
    "    if not batch:\n",
    "        return None  # Retourne None si le batch est vide pour √©viter une erreur\n",
    "\n",
    "    try:\n",
    "        # Extraire les dictionnaires de features et les labels\n",
    "        feature_dicts = [b[0] for b in batch]\n",
    "        labels = [b[1][0] for b in batch]  # On extrait le premier √©l√©ment du tuple des labels\n",
    "\n",
    "        # V√©rifier que les cl√©s essentielles existent dans les features\n",
    "        required_keys = [\"encoder_length\", \"decoder_length\", \"x_cat\", \"x_cont\"]  # Changer \"encoder_lengths\" en \"encoder_length\"\n",
    "        missing_keys = [k for k in required_keys if k not in feature_dicts[0]]\n",
    "\n",
    "        if missing_keys:\n",
    "            raise KeyError(f\"üö® Cl√©s manquantes dans le batch : {missing_keys}\")\n",
    "\n",
    "        # Cr√©ation d'un dictionnaire o√π chaque cl√© est associ√©e √† un tenseur\n",
    "        batch_data = {k: torch.stack([d[k].clone().detach() if isinstance(d[k], torch.Tensor) else torch.tensor(d[k]) for d in feature_dicts]) for k in feature_dicts[0].keys()}\n",
    "\n",
    "        # Conversion des labels en tenseur\n",
    "        batch_labels = torch.stack([label.clone().detach() if isinstance(label, torch.Tensor) else torch.tensor(label) for label in labels])\n",
    "\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üö® Erreur dans `tft_collate_fn`: {e}\")\n",
    "        return None  # Retourne None en cas d'erreur\n",
    "\n",
    "sample_batch = [train_dataset[i] for i in range(10)]\n",
    "collate_result = tft_collate_fn(sample_batch)\n",
    "\n",
    "if collate_result:\n",
    "    print(\"‚úÖ `collate_fn` a bien fonctionn√©. Voici les dimensions des donn√©es :\", {k: v.shape for k, v in collate_result[0].items()})\n",
    "else:\n",
    "    print(\"üö® `collate_fn` a √©chou√©.\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1021cae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning.callbacks import EarlyStopping, TQDMProgressBar\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ‚úÖ Fonction collate corrig√©e\n",
    "def tft_collate_fn(batch):\n",
    "    \"\"\" Collate function pour le mod√®le TFT, en s'assurant que les tailles et types sont coh√©rents. \"\"\"\n",
    "    \n",
    "    batch = [b for b in batch if b is not None]  \n",
    "    if not batch:\n",
    "        return None  # √âviter une erreur si le batch est vide\n",
    "\n",
    "    try:\n",
    "        feature_dicts = [b[0] for b in batch]\n",
    "        labels = [b[1][0] for b in batch]  \n",
    "\n",
    "        # ‚úÖ Correction des noms des cl√©s\n",
    "        required_keys = [\"encoder_length\", \"decoder_length\", \"x_cat\", \"x_cont\"]\n",
    "        missing_keys = [k for k in required_keys if k not in feature_dicts[0]]\n",
    "        if missing_keys:\n",
    "            raise KeyError(f\"üö® Cl√©s manquantes : {missing_keys}\")\n",
    "\n",
    "        batch_data = {\n",
    "            k: torch.stack([\n",
    "                torch.tensor(d[k]) if not isinstance(d[k], torch.Tensor) else d[k].clone().detach()\n",
    "                for d in feature_dicts\n",
    "            ]) \n",
    "            for k in required_keys  # On ne prend que les cl√©s essentielles\n",
    "        }\n",
    "\n",
    "        batch_labels = torch.stack([\n",
    "            torch.tensor(label) if not isinstance(label, torch.Tensor) else label.clone().detach()\n",
    "            for label in labels\n",
    "        ])\n",
    "\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üö® Erreur `tft_collate_fn`: {e}\")\n",
    "        return None  \n",
    "\n",
    "# ‚úÖ V√©rification du dataset\n",
    "try:\n",
    "    sample = train_dataset[0]\n",
    "    print(f\"‚úÖ √âchantillon dataset : {list(sample[0].keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"üö® Erreur lors du chargement du dataset : {e}\")\n",
    "\n",
    "# ‚úÖ Configuration des DataLoaders\n",
    "batch_size = 64\n",
    "num_workers = 0  # ‚ùå √âviter multiprocessing sous Windows\n",
    "pin_memory = torch.cuda.is_available()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=False, \n",
    "    collate_fn=tft_collate_fn, pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False, \n",
    "    collate_fn=tft_collate_fn, pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "# ‚úÖ V√©rification du premier batch\n",
    "try:\n",
    "    test_batch = next(iter(train_dataloader))\n",
    "    if isinstance(test_batch, tuple) or test_batch is None:\n",
    "        print(f\"üö® Erreur : Batch mal structur√© ! Type : {type(test_batch)}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Batch structur√© : Cl√©s = {list(test_batch.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"üö® Erreur lors du chargement du batch : {e}\")\n",
    "\n",
    "# ‚úÖ Callbacks pour l'entra√Ænement\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=True, mode=\"min\")\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "# ‚úÖ D√©finition de l'entra√Æneur\n",
    "trainer = Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator=\"auto\",\n",
    "    enable_progress_bar=True,\n",
    "    enable_checkpointing=False,  \n",
    "    callbacks=[early_stop_callback, progress_bar],  \n",
    "    gradient_clip_val=0.1\n",
    ")\n",
    "\n",
    "# ‚úÖ Lancement de l'entra√Ænement\n",
    "trainer.fit(tft_lightning, train_dataloader, test_dataloader)\n",
    "\n",
    "print(\"‚úÖ Entra√Ænement termin√© avec succ√®s !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e31482",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## 9Ô∏è‚É£ Sauvegarde et chargement du mod√®le   ##\n",
    "#############################################\n",
    "\n",
    "# Sauvegarde du mod√®le\n",
    "model_path = r\"..\\..\\Generated_Files\\TFT\\tft_model.ckpt\"\n",
    "trainer.save_checkpoint(model_path)\n",
    "print(\"Mod√®le sauvegard√© !\")\n",
    "\n",
    "# Chargement du mod√®le\n",
    "tft_loaded = TemporalFusionTransformer.load_from_checkpoint(model_path)\n",
    "print(\"Mod√®le charg√© avec succ√®s !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a09760",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## üîü Pr√©dictions avec le mod√®le           ##\n",
    "#############################################\n",
    "\n",
    "# Faire une pr√©diction sur le test set\n",
    "predictions = tft.predict(test_dataloader, mode=\"prediction\")\n",
    "\n",
    "# Afficher les 10 premi√®res pr√©dictions\n",
    "print(\"Pr√©dictions :\", predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "*********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc891af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba183ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4949fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad2f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42acb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "*********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ee8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "# ‚úÖ Charger le dataset\n",
    "df = pd.read_csv(r\"..\\..\\..\\..\\Datasources\\MetroPT3_new_imputed_final.csv\", delimiter=\",\", decimal=\".\", index_col=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ‚úÖ Convertir timestamp en datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# ‚úÖ D√©finir la date de s√©paration entre Train et Test\n",
    "split_date = \"2020-06-05 23:59:10\"\n",
    "\n",
    "# ‚úÖ S√©parer les donn√©es en train/test\n",
    "df_train = df[df[\"timestamp\"] < split_date].copy()\n",
    "df_test = df[df[\"timestamp\"] >= split_date].copy()\n",
    "\n",
    "# ‚úÖ Recalculer time_idx pour normaliser les valeurs temporelles\n",
    "df_train[\"time_idx\"] = ((df_train[\"timestamp\"] - df_train[\"timestamp\"].min()).dt.total_seconds() // 10).astype(int)\n",
    "df_test[\"time_idx\"] = ((df_test[\"timestamp\"] - df_test[\"timestamp\"].min()).dt.total_seconds() // 10).astype(int)\n",
    "\n",
    "# ‚úÖ D√©finition des colonnes cat√©goriques\n",
    "for col in [\"COMP\", \"DV_eletric\", \"Towers\"]:\n",
    "    df_train[col] = df_train[col].astype(int).astype(str).astype(\"category\")\n",
    "    df_test[col] = df_test[col].astype(int).astype(str).astype(\"category\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Conversion des colonnes cat√©goriques et de panne termin√©e.\")\n",
    "\n",
    "# ‚úÖ G√©n√©rer un group_id plus distinctif\n",
    "df_train[\"group_id\"] = df_train[\"COMP\"].astype(str) + \"_\" + (df_train[\"time_idx\"] // 1000).astype(str)\n",
    "df_test[\"group_id\"] = df_test[\"COMP\"].astype(str) + \"_\" + (df_test[\"time_idx\"] // 1000).astype(str)\n",
    "\n",
    "print(\"‚úÖ group_id ajout√©.\")\n",
    "\n",
    "#  ‚úÖ V√©rifier la correction\n",
    "print(df_test[\"group_id\"].value_counts())  # V√©rifier combien de groupes il y a maintenant\n",
    "print(f\"Nombre de groupes uniques dans df_test : {df_test['group_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dabb1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ D√©finir l'horizon de pr√©vision et la fen√™tre d'observation\n",
    "max_encoder_length = 30  \n",
    "max_prediction_length = 3  \n",
    "\n",
    "# ‚úÖ Cr√©ation du `TimeSeriesDataSet` avec **les bonnes cl√©s**\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    df_train,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"panne\",\n",
    "    group_ids=[\"group_id\"],  \n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_reals=[\"TP2\", \"H1\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\"],\n",
    "    time_varying_known_categoricals=[\"DV_eletric\", \"Towers\"],\n",
    "    categorical_encoders={\"panne\": NaNLabelEncoder(add_nan=True)},\n",
    "    allow_missing_timesteps=True,\n",
    "    target_normalizer=None  # ‚úÖ **√âvite les transformations incorrectes**\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‚úÖ Correction **du probl√®me des cl√©s** en renommant les champs\n",
    "for i in range(len(train_dataset)):\n",
    "    train_dataset[i][0][\"encoder_lengths\"] = train_dataset[i][0].pop(\"encoder_length\")\n",
    "    train_dataset[i][0][\"decoder_lengths\"] = train_dataset[i][0].pop(\"decoder_length\")\n",
    "\n",
    "print(f\"‚úÖ Dataset train corrig√© avec {len(train_dataset)} s√©quences.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caaf2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Correction appliqu√©e aussi au dataset test\n",
    "test_dataset = TimeSeriesDataSet.from_dataset(train_dataset, df_test, predict=True)\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    test_dataset[i][0][\"encoder_lengths\"] = test_dataset[i][0].pop(\"encoder_length\")\n",
    "    test_dataset[i][0][\"decoder_lengths\"] = test_dataset[i][0].pop(\"decoder_length\")\n",
    "\n",
    "print(f\"‚úÖ Dataset test corrig√© avec {len(test_dataset)} s√©quences.\")\n",
    "\n",
    "# ‚úÖ V√©rification de la structure\n",
    "print(f\"‚úÖ Nombre de groupes dans test_dataset: {len(test_dataset.index) if hasattr(test_dataset, 'index') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7ff5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ‚úÖ Cr√©ation des `DataLoader`\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# ‚úÖ V√©rification du premier batch\n",
    "test_batch = next(iter(train_dataloader))\n",
    "print(f\"‚úÖ Batch structur√© : {list(test_batch.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbefc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‚úÖ Entra√Ænement du mod√®le\n",
    "trainer = Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator=\"auto\",\n",
    "    enable_checkpointing=False,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=5)],\n",
    "    gradient_clip_val=0.1\n",
    ")\n",
    "\n",
    "trainer.fit(tft_lightning, train_dataloader, test_dataloader)\n",
    "\n",
    "print(\"‚úÖ Entra√Ænement termin√© avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5879a711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TFT)",
   "language": "python",
   "name": "tft_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
