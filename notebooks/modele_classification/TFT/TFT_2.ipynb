{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b54d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "##                  TFT                  ##\n",
    "###########################################\n",
    "## Chargement des données\n",
    "## Conversion des types\n",
    "## Séparation Train / Test\n",
    "## Préparation des TimeSeriesDataSet\n",
    "## Définition des DataLoaders\n",
    "## Initialisation du modèle TFT\n",
    "## Entraînement du modèle\n",
    "## Sauvegarde et chargement du modèle\n",
    "## Prédiction et affichage des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a0a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "# Charger le dataset\n",
    "df = pd.read_csv(r\"..\\..\\..\\..\\Datasources\\MetroPT3_new_imputed_final.csv\", delimiter=\",\", decimal=\".\", index_col=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac12a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset commence le 2020-04-12 11:20:00 et se termine le 2020-07-17 06:00:00\n",
    "pannes = [\n",
    "    {'id': 'Panne1',  'start': '2020-04-12 11:50:00', 'end': '2020-04-12 23:30:00'},\n",
    "    {'id': 'Panne2',  'start': '2020-04-18 00:00:00', 'end': '2020-04-18 23:59:00'},\n",
    "    {'id': 'Panne3',  'start': '2020-04-19 00:00:00', 'end': '2020-04-19 01:30:00'},\n",
    "    {'id': 'Panne4',  'start': '2020-04-29 03:20:00', 'end': '2020-04-29 04:00:00'},\n",
    "    {'id': 'Panne5',  'start': '2020-04-29 22:00:00', 'end': '2020-04-29 22:20:00'},\n",
    "    {'id': 'Panne6',  'start': '2020-05-13 14:00:00', 'end': '2020-05-13 23:59:00'},\n",
    "    {'id': 'Panne7',  'start': '2020-05-18 05:00:00', 'end': '2020-05-18 05:30:00'},\n",
    "    {'id': 'Panne8',  'start': '2020-05-19 10:10:00', 'end': '2020-05-19 11:00:00'},\n",
    "    {'id': 'Panne9',  'start': '2020-05-19 22:10:00', 'end': '2020-05-19 23:59:00'},\n",
    "    {'id': 'Panne10', 'start': '2020-05-20 00:00:00', 'end': '2020-05-20 20:00:00'},\n",
    "    {'id': 'Panne11', 'start': '2020-05-23 09:50:00', 'end': '2020-05-23 10:10:00'},\n",
    "    {'id': 'Panne12', 'start': '2020-05-29 23:30:00', 'end': '2020-05-29 23:59:00'},\n",
    "    {'id': 'Panne13', 'start': '2020-05-30 00:00:00', 'end': '2020-05-30 06:00:00'},\n",
    "    {'id': 'Panne14', 'start': '2020-06-01 15:00:00', 'end': '2020-06-01 15:40:00'},\n",
    "    {'id': 'Panne15', 'start': '2020-06-03 10:00:00', 'end': '2020-06-03 11:00:00'},\n",
    "    {'id': 'Panne16', 'start': '2020-06-05 10:00:00', 'end': '2020-06-05 23:59:00'},\n",
    "    {'id': 'Panne17', 'start': '2020-06-06 00:00:00', 'end': '2020-06-06 23:59:00'},\n",
    "    {'id': 'Panne18', 'start': '2020-06-07 00:00:00', 'end': '2020-06-07 14:30:00'},\n",
    "    {'id': 'Panne19', 'start': '2020-07-08 17:30:00', 'end': '2020-07-08 19:00:00'},\n",
    "    {'id': 'Panne20', 'start': '2020-07-15 14:30:00', 'end': '2020-07-15 19:00:00'},\n",
    "    {'id': 'Panne21', 'start': '2020-07-17 04:30:00', 'end': '2020-07-17 05:30:00'}\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b852406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir timestamp en datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Définir la date de séparation entre Train et Test\n",
    "split_date = \"2020-06-05 23:59:10\"  # Séparation temporelle (Fin de la panne 16)\n",
    "\n",
    "# Séparer les données en train/test\n",
    "df_train = df[df[\"timestamp\"] < split_date].copy()\n",
    "df_test = df[df[\"timestamp\"] >= split_date].copy()\n",
    "\n",
    "# Recalculer time_idx en divisant par 10 pour éviter les grands nombres\n",
    "df_train[\"time_idx\"] = ((df_train[\"timestamp\"] - df_train[\"timestamp\"].min()).dt.total_seconds() // 10).astype(int)\n",
    "df_test[\"time_idx\"] = ((df_test[\"timestamp\"] - df_test[\"timestamp\"].min()).dt.total_seconds() // 10).astype(int)\n",
    "\n",
    "print(f\"Min time_idx in df_train: {df_train['time_idx'].min()}, Max: {df_train['time_idx'].max()}\")\n",
    "print(f\"Min time_idx in df_test: {df_test['time_idx'].min()}, Max: {df_test['time_idx'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff98fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les colonnes catégoriques et les forcer en str avant de les convertir en category\n",
    "for col in [\"COMP\", \"DV_eletric\", \"Towers\"]:\n",
    "    df_train[col] = df_train[col].astype(int).astype(str).astype(\"category\")\n",
    "    df_test[col] = df_test[col].astype(int).astype(str).astype(\"category\")\n",
    "\n",
    "# Conversion explicite de panne\n",
    "df_train[\"panne\"] = df_train[\"panne\"].astype(int).astype(str).astype(\"category\")\n",
    "df_test[\"panne\"] = df_test[\"panne\"].astype(int).astype(str).astype(\"category\")\n",
    "\n",
    "print(\"Conversion des colonnes catégoriques et de panne terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c2dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter un group_id unique pour tout le dataset\n",
    "df_train[\"group_id\"] = \"compresseur\"\n",
    "df_test[\"group_id\"]  = \"compresseur\"\n",
    "\n",
    "print(\"group_id ajouté.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0222e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les encodeurs pour les variables catégoriques\n",
    "categorical_encoders = {\n",
    "    \"COMP\": NaNLabelEncoder(),\n",
    "    \"DV_eletric\": NaNLabelEncoder(),\n",
    "    \"Towers\": NaNLabelEncoder(),\n",
    "}\n",
    "\n",
    "print(\"Encodeurs catégoriques définis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir l'horizon de prévision et la fenêtre d'observation\n",
    "max_encoder_length = 30  # Fenêtre plus longue pour éviter la suppression\n",
    "max_prediction_length = 3  # Une seule prédiction pour éviter les erreurs\n",
    "\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    df_train,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"panne\",\n",
    "    group_ids=[\"group_id\"],  # Utiliser un ID unique par série\n",
    "    time_varying_known_reals=[\"TP2\", \"H1\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\"],\n",
    "    time_varying_known_categoricals=[\"DV_eletric\", \"Towers\"],\n",
    "    max_encoder_length=30,  \n",
    "    max_prediction_length=3,  \n",
    "    min_encoder_length=10,  # Augmenter pour éviter des séquences trop courtes\n",
    "    min_prediction_length=3,\n",
    "    categorical_encoders=categorical_encoders,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Dataset train créé avec {len(train_dataset)} séquences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TimeSeriesDataSet(\n",
    "    df_test,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"panne\",\n",
    "    group_ids=[\"COMP\"],\n",
    "    time_varying_known_reals=[\"TP2\", \"H1\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\"],\n",
    "    time_varying_known_categoricals=[\"DV_eletric\", \"Towers\"],\n",
    "    max_encoder_length=10,  # Doit être identique à train_dataset\n",
    "    max_prediction_length=3,  # Doit être identique à train_dataset\n",
    "    min_encoder_length=5,\n",
    "    min_prediction_length=2,\n",
    "    categorical_encoders=categorical_encoders,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset test créé avec {len(test_dataset)} séquences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c478f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Nombre de groupes dans test_dataset: {len(test_dataset.index) if hasattr(test_dataset, 'index') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3498b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "# Définition du modèle TFT (Pas besoin de `LightningModule`)\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=1e-3,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# Pas besoin d'assertion sur `LightningModule`\n",
    "print(f\"Modèle TFT initialisé avec {tft.size()} paramètres.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecfe440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "# Création du wrapper LightningModule\n",
    "class TFTLightningModule(LightningModule):\n",
    "    def __init__(self, tft):\n",
    "        super().__init__()\n",
    "        self.model = tft\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self.model(x)\n",
    "        loss = self.model.loss(y_pred, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        if batch is None or \"x\" not in batch or \"y\" not in batch:\n",
    "            print(f\"Batch {batch_idx} mal structuré : {batch}\")\n",
    "            return None  # Évite une erreur bloquante\n",
    "\n",
    "        x = batch[\"x\"]\n",
    "        y = batch[\"y\"]\n",
    "\n",
    "        try:\n",
    "            y_pred = self.model(x)\n",
    "            loss = self.model.loss(y_pred, y)\n",
    "        except KeyError as e:\n",
    "            print(f\"Erreur de clé dans `validation_step`: {e}\")\n",
    "            return None\n",
    "\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.model.configure_optimizers()\n",
    "\n",
    "# Encapsulation du modèle TFT dans `LightningModule`\n",
    "tft_lightning = TFTLightningModule(tft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22541e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def tft_collate_fn(batch):\n",
    "    \"\"\" Collate function pour le modèle TFT, en s'assurant que les tailles et types sont cohérents. \"\"\"\n",
    "    \n",
    "    # Filtrer les échantillons invalides (None)\n",
    "    batch = [b for b in batch if b is not None]  \n",
    "    if not batch:\n",
    "        return None  # Retourne None si le batch est vide pour éviter une erreur\n",
    "\n",
    "    try:\n",
    "        # Extraire les dictionnaires de features et les labels\n",
    "        feature_dicts = [b[0] for b in batch]\n",
    "        labels = [b[1][0] for b in batch]  # On extrait le premier élément du tuple des labels\n",
    "\n",
    "        # Vérifier que les clés essentielles existent dans les features\n",
    "        required_keys = [\"encoder_length\", \"decoder_length\", \"x_cat\", \"x_cont\"]  # Changer \"encoder_lengths\" en \"encoder_length\"\n",
    "        missing_keys = [k for k in required_keys if k not in feature_dicts[0]]\n",
    "\n",
    "        if missing_keys:\n",
    "            raise KeyError(f\"🚨 Clés manquantes dans le batch : {missing_keys}\")\n",
    "\n",
    "        # Création d'un dictionnaire où chaque clé est associée à un tenseur\n",
    "        batch_data = {k: torch.stack([d[k].clone().detach() if isinstance(d[k], torch.Tensor) else torch.tensor(d[k]) for d in feature_dicts]) for k in feature_dicts[0].keys()}\n",
    "\n",
    "        # Conversion des labels en tenseur\n",
    "        batch_labels = torch.stack([label.clone().detach() if isinstance(label, torch.Tensor) else torch.tensor(label) for label in labels])\n",
    "\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 Erreur dans `tft_collate_fn`: {e}\")\n",
    "        return None  # Retourne None en cas d'erreur\n",
    "\n",
    "sample_batch = [train_dataset[i] for i in range(10)]\n",
    "collate_result = tft_collate_fn(sample_batch)\n",
    "\n",
    "if collate_result:\n",
    "    print(\"✅ `collate_fn` a bien fonctionné. Voici les dimensions des données :\", {k: v.shape for k, v in collate_result[0].items()})\n",
    "else:\n",
    "    print(\"🚨 `collate_fn` a échoué.\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1021cae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning.callbacks import EarlyStopping, TQDMProgressBar\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ✅ Fonction collate corrigée\n",
    "def tft_collate_fn(batch):\n",
    "    \"\"\" Collate function pour le modèle TFT, en s'assurant que les tailles et types sont cohérents. \"\"\"\n",
    "    \n",
    "    batch = [b for b in batch if b is not None]  \n",
    "    if not batch:\n",
    "        return None  # Éviter une erreur si le batch est vide\n",
    "\n",
    "    try:\n",
    "        feature_dicts = [b[0] for b in batch]\n",
    "        labels = [b[1][0] for b in batch]  \n",
    "\n",
    "        # ✅ Correction des noms des clés\n",
    "        required_keys = [\"encoder_length\", \"decoder_length\", \"x_cat\", \"x_cont\"]\n",
    "        missing_keys = [k for k in required_keys if k not in feature_dicts[0]]\n",
    "        if missing_keys:\n",
    "            raise KeyError(f\"🚨 Clés manquantes : {missing_keys}\")\n",
    "\n",
    "        batch_data = {\n",
    "            k: torch.stack([\n",
    "                torch.tensor(d[k]) if not isinstance(d[k], torch.Tensor) else d[k].clone().detach()\n",
    "                for d in feature_dicts\n",
    "            ]) \n",
    "            for k in required_keys  # On ne prend que les clés essentielles\n",
    "        }\n",
    "\n",
    "        batch_labels = torch.stack([\n",
    "            torch.tensor(label) if not isinstance(label, torch.Tensor) else label.clone().detach()\n",
    "            for label in labels\n",
    "        ])\n",
    "\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 Erreur `tft_collate_fn`: {e}\")\n",
    "        return None  \n",
    "\n",
    "# ✅ Vérification du dataset\n",
    "try:\n",
    "    sample = train_dataset[0]\n",
    "    print(f\"✅ Échantillon dataset : {list(sample[0].keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"🚨 Erreur lors du chargement du dataset : {e}\")\n",
    "\n",
    "# ✅ Configuration des DataLoaders\n",
    "batch_size = 64\n",
    "num_workers = 0  # ❌ Éviter multiprocessing sous Windows\n",
    "pin_memory = torch.cuda.is_available()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=False, \n",
    "    collate_fn=tft_collate_fn, pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False, \n",
    "    collate_fn=tft_collate_fn, pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "# ✅ Vérification du premier batch\n",
    "try:\n",
    "    test_batch = next(iter(train_dataloader))\n",
    "    if isinstance(test_batch, tuple) or test_batch is None:\n",
    "        print(f\"🚨 Erreur : Batch mal structuré ! Type : {type(test_batch)}\")\n",
    "    else:\n",
    "        print(f\"✅ Batch structuré : Clés = {list(test_batch.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"🚨 Erreur lors du chargement du batch : {e}\")\n",
    "\n",
    "# ✅ Callbacks pour l'entraînement\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=True, mode=\"min\")\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "# ✅ Définition de l'entraîneur\n",
    "trainer = Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator=\"auto\",\n",
    "    enable_progress_bar=True,\n",
    "    enable_checkpointing=False,  \n",
    "    callbacks=[early_stop_callback, progress_bar],  \n",
    "    gradient_clip_val=0.1\n",
    ")\n",
    "\n",
    "# ✅ Lancement de l'entraînement\n",
    "trainer.fit(tft_lightning, train_dataloader, test_dataloader)\n",
    "\n",
    "print(\"✅ Entraînement terminé avec succès !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e31482",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## 9️⃣ Sauvegarde et chargement du modèle   ##\n",
    "#############################################\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "model_path = r\"..\\..\\Generated_Files\\TFT\\tft_model.ckpt\"\n",
    "trainer.save_checkpoint(model_path)\n",
    "print(\"Modèle sauvegardé !\")\n",
    "\n",
    "# Chargement du modèle\n",
    "tft_loaded = TemporalFusionTransformer.load_from_checkpoint(model_path)\n",
    "print(\"Modèle chargé avec succès !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a09760",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## 🔟 Prédictions avec le modèle           ##\n",
    "#############################################\n",
    "\n",
    "# Faire une prédiction sur le test set\n",
    "predictions = tft.predict(test_dataloader, mode=\"prediction\")\n",
    "\n",
    "# Afficher les 10 premières prédictions\n",
    "print(\"Prédictions :\", predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "*********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc891af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba183ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4949fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad2f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42acb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "*********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ee8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "# ✅ Charger le dataset\n",
    "df = pd.read_csv(r\"..\\..\\..\\..\\Datasources\\MetroPT3_new_imputed_final.csv\", delimiter=\",\", decimal=\".\", index_col=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ✅ Convertir timestamp en datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# ✅ Définir la date de séparation entre Train et Test\n",
    "split_date = \"2020-06-05 23:59:10\"\n",
    "\n",
    "# ✅ Séparer les données en train/test\n",
    "df_train = df[df[\"timestamp\"] < split_date].copy()\n",
    "df_test = df[df[\"timestamp\"] >= split_date].copy()\n",
    "\n",
    "# ✅ Recalculer time_idx pour normaliser les valeurs temporelles\n",
    "df_train[\"time_idx\"] = ((df_train[\"timestamp\"] - df_train[\"timestamp\"].min()).dt.total_seconds() // 10).astype(int)\n",
    "df_test[\"time_idx\"] = ((df_test[\"timestamp\"] - df_test[\"timestamp\"].min()).dt.total_seconds() // 10).astype(int)\n",
    "\n",
    "# ✅ Définition des colonnes catégoriques\n",
    "for col in [\"COMP\", \"DV_eletric\", \"Towers\"]:\n",
    "    df_train[col] = df_train[col].astype(int).astype(str).astype(\"category\")\n",
    "    df_test[col] = df_test[col].astype(int).astype(str).astype(\"category\")\n",
    "\n",
    "\n",
    "print(\"✅ Conversion des colonnes catégoriques et de panne terminée.\")\n",
    "\n",
    "# ✅ Générer un group_id plus distinctif\n",
    "df_train[\"group_id\"] = df_train[\"COMP\"].astype(str) + \"_\" + (df_train[\"time_idx\"] // 1000).astype(str)\n",
    "df_test[\"group_id\"] = df_test[\"COMP\"].astype(str) + \"_\" + (df_test[\"time_idx\"] // 1000).astype(str)\n",
    "\n",
    "print(\"✅ group_id ajouté.\")\n",
    "\n",
    "#  ✅ Vérifier la correction\n",
    "print(df_test[\"group_id\"].value_counts())  # Vérifier combien de groupes il y a maintenant\n",
    "print(f\"Nombre de groupes uniques dans df_test : {df_test['group_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dabb1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Définir l'horizon de prévision et la fenêtre d'observation\n",
    "max_encoder_length = 30  \n",
    "max_prediction_length = 3  \n",
    "\n",
    "# ✅ Création du `TimeSeriesDataSet` avec **les bonnes clés**\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    df_train,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"panne\",\n",
    "    group_ids=[\"group_id\"],  \n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_reals=[\"TP2\", \"H1\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\"],\n",
    "    time_varying_known_categoricals=[\"DV_eletric\", \"Towers\"],\n",
    "    categorical_encoders={\"panne\": NaNLabelEncoder(add_nan=True)},\n",
    "    allow_missing_timesteps=True,\n",
    "    target_normalizer=None  # ✅ **Évite les transformations incorrectes**\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ Correction **du problème des clés** en renommant les champs\n",
    "for i in range(len(train_dataset)):\n",
    "    train_dataset[i][0][\"encoder_lengths\"] = train_dataset[i][0].pop(\"encoder_length\")\n",
    "    train_dataset[i][0][\"decoder_lengths\"] = train_dataset[i][0].pop(\"decoder_length\")\n",
    "\n",
    "print(f\"✅ Dataset train corrigé avec {len(train_dataset)} séquences.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caaf2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Correction appliquée aussi au dataset test\n",
    "test_dataset = TimeSeriesDataSet.from_dataset(train_dataset, df_test, predict=True)\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    test_dataset[i][0][\"encoder_lengths\"] = test_dataset[i][0].pop(\"encoder_length\")\n",
    "    test_dataset[i][0][\"decoder_lengths\"] = test_dataset[i][0].pop(\"decoder_length\")\n",
    "\n",
    "print(f\"✅ Dataset test corrigé avec {len(test_dataset)} séquences.\")\n",
    "\n",
    "# ✅ Vérification de la structure\n",
    "print(f\"✅ Nombre de groupes dans test_dataset: {len(test_dataset.index) if hasattr(test_dataset, 'index') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7ff5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ✅ Création des `DataLoader`\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# ✅ Vérification du premier batch\n",
    "test_batch = next(iter(train_dataloader))\n",
    "print(f\"✅ Batch structuré : {list(test_batch.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbefc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ Entraînement du modèle\n",
    "trainer = Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator=\"auto\",\n",
    "    enable_checkpointing=False,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=5)],\n",
    "    gradient_clip_val=0.1\n",
    ")\n",
    "\n",
    "trainer.fit(tft_lightning, train_dataloader, test_dataloader)\n",
    "\n",
    "print(\"✅ Entraînement terminé avec succès !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5879a711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TFT)",
   "language": "python",
   "name": "tft_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
