{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c9cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer import TemporalFusionTransformer\n",
    "\n",
    "print(\"Torch version :\", torch.__version__)\n",
    "print(\"Pandas version :\", pd.__version__)\n",
    "print(\"NumPy version :\", np.__version__)\n",
    "print(\"TFT installé correctement !\")\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ceb6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données MetroPT-3\n",
    "df = pd.read_csv(r\"..\\..\\..\\..\\Datasources\\MetroPT3_new_imputed_final.csv\", delimiter=\",\", decimal=\".\", index_col=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9679a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la colonne 'timestamp' en type datetime\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Définir les colonnes continues et catégoriques pour l'entrainement\n",
    "continuous_features  = [\"TP2\",\"H1\",\"DV_pressure\", \"Oil_temperature\", \"Motor_current\"]\n",
    "categorical_features = [\"COMP\", \"DV_eletric\", \"Towers\"]\n",
    "\n",
    "# Convertir les colonnes catégoriques en type \"category\"\n",
    "for col in categorical_features:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# Convertir la colonne 'panne' en type category\n",
    "df['panne'] = df['panne'].astype('category')\n",
    "\n",
    "# Liste des colonnes nécessaires\n",
    "columns_to_keep = [\"timestamp\"] + continuous_features + [\"panne\"] + categorical_features\n",
    "\n",
    "# Réduire le DataFrame\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# Afficher les premières lignes pour vérifier\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac12a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset commence le 2020-04-12 11:20:00 et se termine le 2020-07-17 06:00:00\n",
    "pannes = [\n",
    "    {'id': 'Panne1',  'start': '2020-04-12 11:50:00', 'end': '2020-04-12 23:30:00'},\n",
    "    {'id': 'Panne2',  'start': '2020-04-18 00:00:00', 'end': '2020-04-18 23:59:00'},\n",
    "    {'id': 'Panne3',  'start': '2020-04-19 00:00:00', 'end': '2020-04-19 01:30:00'},\n",
    "    {'id': 'Panne4',  'start': '2020-04-29 03:20:00', 'end': '2020-04-29 04:00:00'},\n",
    "    {'id': 'Panne5',  'start': '2020-04-29 22:00:00', 'end': '2020-04-29 22:20:00'},\n",
    "    {'id': 'Panne6',  'start': '2020-05-13 14:00:00', 'end': '2020-05-13 23:59:00'},\n",
    "    {'id': 'Panne7',  'start': '2020-05-18 05:00:00', 'end': '2020-05-18 05:30:00'},\n",
    "    {'id': 'Panne8',  'start': '2020-05-19 10:10:00', 'end': '2020-05-19 11:00:00'},\n",
    "    {'id': 'Panne9',  'start': '2020-05-19 22:10:00', 'end': '2020-05-19 23:59:00'},\n",
    "    {'id': 'Panne10', 'start': '2020-05-20 00:00:00', 'end': '2020-05-20 20:00:00'},\n",
    "    {'id': 'Panne11', 'start': '2020-05-23 09:50:00', 'end': '2020-05-23 10:10:00'},\n",
    "    {'id': 'Panne12', 'start': '2020-05-29 23:30:00', 'end': '2020-05-29 23:59:00'},\n",
    "    {'id': 'Panne13', 'start': '2020-05-30 00:00:00', 'end': '2020-05-30 06:00:00'},\n",
    "    {'id': 'Panne14', 'start': '2020-06-01 15:00:00', 'end': '2020-06-01 15:40:00'},\n",
    "    {'id': 'Panne15', 'start': '2020-06-03 10:00:00', 'end': '2020-06-03 11:00:00'},\n",
    "    {'id': 'Panne16', 'start': '2020-06-05 10:00:00', 'end': '2020-06-05 23:59:00'},\n",
    "    {'id': 'Panne17', 'start': '2020-06-06 00:00:00', 'end': '2020-06-06 23:59:00'},\n",
    "    {'id': 'Panne18', 'start': '2020-06-07 00:00:00', 'end': '2020-06-07 14:30:00'},\n",
    "    {'id': 'Panne19', 'start': '2020-07-08 17:30:00', 'end': '2020-07-08 19:00:00'},\n",
    "    {'id': 'Panne20', 'start': '2020-07-15 14:30:00', 'end': '2020-07-15 19:00:00'},\n",
    "    {'id': 'Panne21', 'start': '2020-07-17 04:30:00', 'end': '2020-07-17 05:30:00'}\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e27161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation Train/Test et Conversion de time_idx\n",
    "\n",
    "\n",
    "# Définir la date de séparation entre Train et Test\n",
    "split_date = \"2020-06-05 23:59:10\"  # Séparation temporelle (Fin de la panne 16)\n",
    "\n",
    "# Séparer les données en train/test\n",
    "df_train = df[df[\"timestamp\"] < split_date].copy()\n",
    "df_test = df[df[\"timestamp\"] >= split_date].copy()\n",
    "\n",
    "# Transformer la colonne timestamp en index numérique basé sur le temps écoulé\n",
    "df_train[\"time_idx\"] = (df_train[\"timestamp\"] - df[\"timestamp\"].min()).dt.total_seconds().astype(int)\n",
    "df_test[\"time_idx\"] = (df_test[\"timestamp\"] - df[\"timestamp\"].min()).dt.total_seconds().astype(int)\n",
    "\n",
    "# Trier les données pour s'assurer de l'ordre temporel\n",
    "df_train = df_train.sort_values(by=[\"COMP\", \"time_idx\"]).reset_index(drop=True)\n",
    "df_test = df_test.sort_values(by=[\"COMP\", \"time_idx\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Entraînement : {len(df_train)} lignes | Test : {len(df_test)} lignes\")\n",
    "print(\"Conversion de timestamp en index temporel terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification des Groupes et des Données\n",
    "\n",
    "# Vérifier que COMP est bien une catégorie\n",
    "df_train[\"COMP\"] = df_train[\"COMP\"].astype(str).astype(\"category\")\n",
    "df_test[\"COMP\"] = df_test[\"COMP\"].astype(str).astype(\"category\")\n",
    "\n",
    "print(f\"Groupes uniques dans df_train : {df_train['COMP'].unique()}\")\n",
    "print(f\"Groupes uniques dans df_test : {df_test['COMP'].unique()}\")\n",
    "\n",
    "# Vérifier combien de timestamps uniques par groupe\n",
    "grouped_counts_test = df_test.groupby([\"COMP\"])[\"time_idx\"].nunique()\n",
    "print(\"Timestamps uniques par groupe dans df_test :\", grouped_counts_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b6428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des Encodeurs Catégoriques\n",
    "\n",
    "# Convertir les colonnes catégoriques en chaînes de caractères pour PyTorch Forecasting\n",
    "categorical_features = [\"COMP\", \"DV_eletric\", \"Towers\"]\n",
    "\n",
    "for col in categorical_features:\n",
    "    df_train[col] = df_train[col].astype(str).astype(\"category\")\n",
    "    df_test[col] = df_test[col].astype(str).astype(\"category\")\n",
    "\n",
    "    \n",
    "print(\"Les colonnes catégoriques sont bien en chaînes de caractères.\")\n",
    "# Définir les encodeurs pour les variables catégoriques\n",
    "categorical_encoders = {\n",
    "    \"COMP\": NaNLabelEncoder(),\n",
    "    \"DV_eletric\": NaNLabelEncoder(),\n",
    "    \"Towers\": NaNLabelEncoder(),\n",
    "}\n",
    "\n",
    "print(\"Encodeurs catégoriques définis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b62de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des Datasets pour TFT\n",
    "\n",
    "# Démarrer le chronometre\n",
    "start_time = time.time()\n",
    "\n",
    "# Définir l'horizon de prévision et la fenêtre d'observation\n",
    "max_encoder_length = 5  # Réduction pour s'assurer d'avoir assez de séquences\n",
    "max_prediction_length = 2 # Réduction pour éviter les suppressions de séries\n",
    "\n",
    "\n",
    "df_train[\"COMP\"] = df_train[\"COMP\"].astype(str).astype(\"category\")\n",
    "df_train[\"Towers\"] = df_train[\"Towers\"].astype(str).astype(\"category\")\n",
    "\n",
    "\n",
    "# Vérifier si certaines séquences sont trop courtes pour être utilisées\n",
    "for comp in df_test[\"COMP\"].unique():\n",
    "    subset = df_test[df_test[\"COMP\"] == comp]\n",
    "    unique_timestamps = subset[\"time_idx\"].nunique()\n",
    "    if unique_timestamps < (max_encoder_length + max_prediction_length):\n",
    "        print(f\"⚠ Série COMP={comp} est trop courte avec {unique_timestamps} points !\")\n",
    "    else:\n",
    "        print(f\"Série COMP={comp} est suffisante avec {unique_timestamps} points.\")\n",
    "\n",
    "      \n",
    "\n",
    "# Création du dataset pour TFT (Train)\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    df_train,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"panne\",\n",
    "    group_ids=[\"COMP\"],  \n",
    "    time_varying_known_reals=[\"TP2\", \"H1\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\"],\n",
    "    time_varying_known_categoricals=[\"DV_eletric\", \"Towers\"],\n",
    "    max_encoder_length=10,\n",
    "    max_prediction_length=3,\n",
    "    min_encoder_length=5,  \n",
    "    min_prediction_length=2,\n",
    "    categorical_encoders=categorical_encoders,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset train créé avec {len(train_dataset)} séquences.\")\n",
    "\n",
    "\n",
    "# Création du dataset pour TFT (Test)\n",
    "test_dataset = TimeSeriesDataSet(\n",
    "    df_test,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"panne\",\n",
    "    group_ids=[\"COMP\"],  \n",
    "    time_varying_known_reals=[\"TP2\", \"H1\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\"],\n",
    "    time_varying_known_categoricals=[\"DV_eletric\", \"Towers\"],\n",
    "    max_encoder_length=10,\n",
    "    max_prediction_length=3,\n",
    "    categorical_encoders=categorical_encoders,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "# Vérifier les tailles des datasets\n",
    "print(f\"Train dataset: {len(train_dataset)} séquences | Test dataset: {len(test_dataset)} séquences\")\n",
    "\n",
    "# Arrêter le chronomètre\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'exécution: {end_time - start_time:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd40d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des Datasets pour TFT\n",
    "\n",
    "# Définir l'horizon de prévision et la fenêtre d'observation\n",
    "max_encoder_length = 10  # Réduction pour s'assurer d'avoir assez de séquences\n",
    "max_prediction_length = 3 # Réduction pour éviter les suppressions de séries\n",
    "\n",
    "\n",
    "# Création du dataset pour TFT (Train)\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    df_train,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"panne\",\n",
    "    group_ids=[\"COMP\"],  \n",
    "    time_varying_known_reals=[\"TP2\", \"H1\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\"],\n",
    "    time_varying_known_categoricals=[\"DV_eletric\", \"Towers\"],\n",
    "    max_encoder_length=10,\n",
    "    max_prediction_length=3,\n",
    "    min_encoder_length=5,  \n",
    "    min_prediction_length=2,\n",
    "    categorical_encoders=categorical_encoders,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "print(f\"✅ Dataset train créé avec {len(train_dataset)} séquences.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2eb4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"group_id\"] = \"compresseur\"  # ✅ Définir un group_id unique\n",
    "\n",
    "test_dataset = TimeSeriesDataSet(\n",
    "    df_test,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"panne\",\n",
    "    group_ids=[\"group_id\"],  # ✅ Modifier group_ids pour correspondre à l'approche du document\n",
    "    time_varying_known_reals=[\"TP2\", \"H1\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\"],\n",
    "    time_varying_known_categoricals=[\"DV_eletric\", \"Towers\"],\n",
    "    max_encoder_length=5,\n",
    "    max_prediction_length=2,\n",
    "    categorical_encoders=categorical_encoders,\n",
    "    allow_missing_timesteps=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d11760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd5ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c09b659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a9def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c517223f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les DataLoaders\n",
    "\n",
    "# Démarrer le chronometre\n",
    "start_time = time.time()\n",
    "\n",
    "# Création des DataLoaders pour l'entraînement et le test\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=64, shuffle=True, num_workers=0\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=64, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "# Arrêter le chronometre\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'exécution: {end_time - start_time:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad272d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir et entraîner le modèle TFT\n",
    "\n",
    "# Démarrer le chronometre\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Définition du modèle TFT\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=0.01,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    output_size=7,  # Nombre de quantiles\n",
    "    loss=QuantileLoss(),\n",
    "    logging_metrics=[],\n",
    ")\n",
    "\n",
    "# Configuration du Trainer avec EarlyStopping\n",
    "trainer = Trainer(\n",
    "    max_epochs=30,\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=5)],\n",
    ")\n",
    "\n",
    "# Entraînement du modèle\n",
    "trainer.fit(\n",
    "    tft, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader\n",
    ")\n",
    "\n",
    "print(\" Entraînement terminé.\")\n",
    "\n",
    "\n",
    "\n",
    "# Arrêter le chronometre\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'exécution: {end_time - start_time:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c679ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire des prédictions et identifier les pannes imminentes\n",
    "\n",
    "# Démarrer le chronometre\n",
    "start_time = time.time()\n",
    "\n",
    "# Générer des prédictions sur le jeu de test\n",
    "raw_predictions, x = tft_loaded.predict(test_dataloader, return_x=True)\n",
    "\n",
    "# Transformer les prédictions en DataFrame\n",
    "pred_df = pd.DataFrame({\n",
    "    \"timestamp\": x[\"encoder_time_idx\"][:, -1].cpu().numpy(),\n",
    "    \"panne_predite\": raw_predictions[:, 0].cpu().numpy(),\n",
    "})\n",
    "\n",
    "# Afficher les résultats des prédictions\n",
    "print(pred_df.head(10))\n",
    "\n",
    "# Visualisation des pannes anticipées sur le jeu de test\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df_test[\"timestamp\"], df_test[\"panne\"], label=\"Réel\", color=\"blue\")\n",
    "plt.plot(pred_df[\"timestamp\"], pred_df[\"panne_predite\"], label=\"Prédit\", color=\"red\")\n",
    "plt.xlabel(\"Temps\")\n",
    "plt.ylabel(\"Panne (0 = normal, 2 = pré-panne, 1 = panne)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Arrêter le chronometre\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'exécution: {end_time - start_time:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e95c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle entrainé\n",
    "\n",
    "# Démarrer le chronometre\n",
    "start_time = time.time()\n",
    "\n",
    "model_path = r\"..\\..\\Generated_Files\\TFT\\tft_model.pth\"  \n",
    "torch.save(tft.state_dict(), model_path)\n",
    "print(f\"Modèle sauvegardé sous : {model_path}\")\n",
    "\n",
    "# Arrêter le chronometre\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'exécution: {end_time - start_time:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f959c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recharger le modèle entrainé\n",
    "\n",
    "# Démarrer le chronometre\n",
    "start_time = time.time()\n",
    "\n",
    "tft_loaded = TemporalFusionTransformer.from_dataset(train_dataset)\n",
    "\n",
    "# Charger les poids du modèle sauvegardé\n",
    "tft_loaded.load_state_dict(torch.load(r\"..\\..\\Generated_Files\\TFT\\tft_model.pth\"))\n",
    "tft_loaded.eval()   # Mettre le modèle en mode évaluation\n",
    "\n",
    "print(\"Modèle chargé avec succès !\")\n",
    "\n",
    "# Arrêter le chronometre\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'exécution: {end_time - start_time:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1982a6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b0222a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e2756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d0cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "***********************************************************************************\n",
    "***********************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "384a0a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min time_idx in df_train: 0, Max: 471114\n",
      "Min time_idx in df_test: 0, Max: 356405\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "# Charger le dataset\n",
    "df = pd.read_csv(r\"..\\..\\..\\..\\Datasources\\MetroPT3_new_imputed_final.csv\", delimiter=\",\", decimal=\".\", index_col=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convertir timestamp en datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Définir la date de séparation entre Train et Test\n",
    "split_date = \"2020-06-05 23:59:10\"  # Séparation temporelle (Fin de la panne 16)\n",
    "\n",
    "# Séparer les données en train/test\n",
    "df_train = df[df[\"timestamp\"] < split_date].copy()\n",
    "df_test = df[df[\"timestamp\"] >= split_date].copy()\n",
    "\n",
    "# Recalculer time_idx en divisant par 10 pour éviter les grands nombres\n",
    "df_train[\"time_idx\"] = ((df_train[\"timestamp\"] - df_train[\"timestamp\"].min()).dt.total_seconds() // 10).astype(int)\n",
    "df_test[\"time_idx\"] = ((df_test[\"timestamp\"] - df_test[\"timestamp\"].min()).dt.total_seconds() // 10).astype(int)\n",
    "\n",
    "print(f\"Min time_idx in df_train: {df_train['time_idx'].min()}, Max: {df_train['time_idx'].max()}\")\n",
    "print(f\"Min time_idx in df_test: {df_test['time_idx'].min()}, Max: {df_test['time_idx'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff98fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion des colonnes catégoriques et de panne terminée.\n"
     ]
    }
   ],
   "source": [
    "# Définir les colonnes catégoriques et les forcer en str avant de les convertir en category\n",
    "for col in [\"COMP\", \"DV_eletric\", \"Towers\"]:\n",
    "    df_train[col] = df_train[col].astype(int).astype(str).astype(\"category\")\n",
    "    df_test[col] = df_test[col].astype(int).astype(str).astype(\"category\")\n",
    "\n",
    "# Conversion explicite de panne\n",
    "df_train[\"panne\"] = df_train[\"panne\"].astype(int).astype(str).astype(\"category\")\n",
    "df_test[\"panne\"] = df_test[\"panne\"].astype(int).astype(str).astype(\"category\")\n",
    "\n",
    "print(\"Conversion des colonnes catégoriques et de panne terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f9c2dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_id ajouté.\n"
     ]
    }
   ],
   "source": [
    "# Ajouter un group_id unique pour tout le dataset\n",
    "df_train[\"group_id\"] = \"compresseur\"\n",
    "df_test[\"group_id\"] = \"compresseur\"\n",
    "\n",
    "print(\"group_id ajouté.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0222e1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encodeurs catégoriques définis.\n"
     ]
    }
   ],
   "source": [
    "# Définir les encodeurs pour les variables catégoriques\n",
    "categorical_encoders = {\n",
    "    \"COMP\": NaNLabelEncoder(),\n",
    "    \"DV_eletric\": NaNLabelEncoder(),\n",
    "    \"Towers\": NaNLabelEncoder(),\n",
    "}\n",
    "\n",
    "print(\"Encodeurs catégoriques définis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "612b8d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset train créé avec 476698 séquences.\n"
     ]
    }
   ],
   "source": [
    "# Définir l'horizon de prévision et la fenêtre d'observation\n",
    "max_encoder_length = 30  # Fenêtre plus longue pour éviter la suppression\n",
    "max_prediction_length = 1  # Une seule prédiction pour éviter les erreurs\n",
    "\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    df_train,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"panne\",\n",
    "    group_ids=[\"COMP\"],\n",
    "    time_varying_known_reals=[\"TP2\", \"H1\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\"],\n",
    "    time_varying_known_categoricals=[\"DV_eletric\", \"Towers\"],\n",
    "    max_encoder_length=10,\n",
    "    max_prediction_length=3,\n",
    "    min_encoder_length=5,\n",
    "    min_prediction_length=2,\n",
    "    categorical_encoders=categorical_encoders,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset train créé avec {len(train_dataset)} séquences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f185cc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset test créé avec 357868 séquences.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TimeSeriesDataSet(\n",
    "    df_test,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"panne\",\n",
    "    group_ids=[\"COMP\"],\n",
    "    time_varying_known_reals=[\"TP2\", \"H1\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\"],\n",
    "    time_varying_known_categoricals=[\"DV_eletric\", \"Towers\"],\n",
    "    max_encoder_length=10,  # Doit être identique à train_dataset\n",
    "    max_prediction_length=3,  # Doit être identique à train_dataset\n",
    "    min_encoder_length=5,\n",
    "    min_prediction_length=2,\n",
    "    categorical_encoders=categorical_encoders,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset test créé avec {len(test_dataset)} séquences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c478f7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de groupes dans test_dataset: 357868\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nombre de groupes dans test_dataset: {len(test_dataset.index) if hasattr(test_dataset, 'index') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3498b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle TFT initialisé avec 21007 paramètres.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\__init__.py:171: UserWarning: In pytorch-forecasting models, on versions 1.1.X, the default optimizer defaults to 'adam', if pytorch_optimizer is not installed, otherwise it defaults to 'ranger' from pytorch_optimizer. From version 1.2.0, the default optimizer will be 'adam' regardless of whether pytorch_optimizer is installed, in order to minimize the number of dependencies in default parameter settings. Users who wish to ensure their code continues using 'ranger' as optimizer should ensure that pytorch_optimizer is installed, and set the optimizer parameter explicitly to 'ranger'.\n",
      "  super().__init__(loss=loss, logging_metrics=logging_metrics, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "# Définition du modèle TFT (Pas besoin de `LightningModule`)\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=1e-3,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# Pas besoin d'assertion sur `LightningModule`\n",
    "print(f\"Modèle TFT initialisé avec {tft.size()} paramètres.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eecfe440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "# Création du wrapper LightningModule\n",
    "class TFTLightningModule(LightningModule):\n",
    "    def __init__(self, tft):\n",
    "        super().__init__()\n",
    "        self.model = tft\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self.model(x)\n",
    "        loss = self.model.loss(y_pred, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        if batch is None or not batch:\n",
    "            print(f\"❌ Batch {batch_idx} est VIDE dans validation_step()\")\n",
    "            return None  #  Évite une erreur bloquante\n",
    "\n",
    "        # Vérifie la structure du batch\n",
    "        if \"x\" not in batch or \"y\" not in batch:\n",
    "            print(f\"❌ Batch {batch_idx} mal structuré : {batch}\")\n",
    "            return None\n",
    "\n",
    "        x = batch[\"x\"]\n",
    "        y = batch[\"y\"]\n",
    "\n",
    "        y_pred = self.model(x)\n",
    "        loss = self.model.loss(y_pred, y)\n",
    "\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.model.configure_optimizers()\n",
    "\n",
    "# Encapsulation du modèle TFT dans `LightningModule`\n",
    "tft_lightning = TFTLightningModule(tft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1021cae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur dans `collate_fn`: stack expects each tensor to be equal size, but got [13, 2] at entry 0 and [12, 2] at entry 1\n",
      "✅ Batch 0 est un dictionnaire contenant ['x', 'y']\n",
      "Erreur dans `collate_fn`: stack expects each tensor to be equal size, but got [13, 2] at entry 0 and [7, 2] at entry 6\n",
      "✅ Batch 1 est un dictionnaire contenant ['x', 'y']\n",
      "Erreur dans `collate_fn`: stack expects each tensor to be equal size, but got [13, 2] at entry 0 and [11, 2] at entry 5\n",
      "✅ Batch 2 est un dictionnaire contenant ['x', 'y']\n",
      "Erreur dans `collate_fn`: stack expects each tensor to be equal size, but got [10, 2] at entry 0 and [13, 2] at entry 1\n",
      "✅ Batch 3 est un dictionnaire contenant ['x', 'y']\n",
      "Erreur dans `collate_fn`: stack expects each tensor to be equal size, but got [13, 2] at entry 0 and [8, 2] at entry 1\n",
      "✅ Batch 4 est un dictionnaire contenant ['x', 'y']\n",
      "Erreur dans `collate_fn`: stack expects each tensor to be equal size, but got [13, 2] at entry 0 and [12, 2] at entry 4\n",
      "✅ Batch 5 est un dictionnaire contenant ['x', 'y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur dans `collate_fn`: stack expects each tensor to be equal size, but got [13, 2] at entry 0 and [12, 2] at entry 1\n",
      "✅ Batch 0 est un dictionnaire contenant ['x', 'y'] avec 1 échantillons\n",
      "Erreur dans `collate_fn`: stack expects each tensor to be equal size, but got [13, 2] at entry 0 and [10, 2] at entry 15\n",
      "✅ Batch 1 est un dictionnaire contenant ['x', 'y'] avec 1 échantillons\n",
      "Erreur dans `collate_fn`: stack expects each tensor to be equal size, but got [13, 2] at entry 0 and [12, 2] at entry 3\n",
      "✅ Batch 2 est un dictionnaire contenant ['x', 'y'] avec 1 échantillons\n",
      "Erreur dans `collate_fn`: stack expects each tensor to be equal size, but got [13, 2] at entry 0 and [12, 2] at entry 8\n",
      "✅ Batch 3 est un dictionnaire contenant ['x', 'y'] avec 1 échantillons\n",
      "Erreur dans `collate_fn`: stack expects each tensor to be equal size, but got [13, 2] at entry 0 and [11, 2] at entry 11\n",
      "✅ Batch 4 est un dictionnaire contenant ['x', 'y'] avec 1 échantillons\n",
      "Erreur dans `collate_fn`: stack expects each tensor to be equal size, but got [7, 2] at entry 0 and [13, 2] at entry 1\n",
      "✅ Batch 5 est un dictionnaire contenant ['x', 'y'] avec 1 échantillons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                      | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | model | TemporalFusionTransformer | 21.0 K | train\n",
      "------------------------------------------------------------\n",
      "21.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.0 K    Total params\n",
      "0.084     Total estimated model params size (MB)\n",
      "326       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df93cf3bfba04a8ab3fc30e9cdfe3cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur dans `collate_fn`: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'encoder_lengths'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 85\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Entraînement du modèle\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtft_lightning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntraînement terminé avec succès !\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    571\u001b[0m     ckpt_path,\n\u001b[0;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    574\u001b[0m )\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:982\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 982\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    987\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1024\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1024\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1026\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1053\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1050\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:179\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:144\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:433\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[0;32m    427\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    428\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[0;32m    432\u001b[0m )\n\u001b[1;32m--> 433\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:323\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 323\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    326\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:412\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 32\u001b[0m, in \u001b[0;36mTFTLightningModule.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     30\u001b[0m y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 32\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mloss(y_pred, y)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss}\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\ProjetSynthese\\Modele1_Classification\\TFT\\tft_env\\Lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\__init__.py:430\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    427\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03m    input dimensions: n_samples x time x variables\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m     encoder_lengths \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoder_lengths\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    431\u001b[0m     decoder_lengths \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_lengths\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    432\u001b[0m     x_cat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_cat\u001b[39m\u001b[38;5;124m\"\u001b[39m], x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_cat\u001b[39m\u001b[38;5;124m\"\u001b[39m]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# concatenate in time dimension\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'encoder_lengths'"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping, TQDMProgressBar\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import torch\n",
    "\n",
    "def tft_collate_fn(batch):\n",
    "    batch = [b for b in batch if b is not None]  # Supprime les batchs `None`\n",
    "\n",
    "    if len(batch) == 0:\n",
    "        print(\"⚠ Avertissement : Un batch vide a été détecté. Il sera remplacé par des zéros.\")\n",
    "        return {\n",
    "            \"x\": {\n",
    "                \"x_cat\": torch.zeros((1, 2), dtype=torch.long),  # Ajuste selon le nombre de variables catégoriques\n",
    "                \"x_cont\": torch.zeros((1, 5), dtype=torch.float32)  # Ajuste selon le nombre de variables continues\n",
    "            },\n",
    "            \"y\": torch.zeros((1, 1), dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        inputs, targets = zip(*batch)  # Sépare les entrées (x) et les cibles (y)\n",
    "        return {\n",
    "            \"x\": default_collate(inputs),\n",
    "            \"y\": default_collate(targets)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur dans `collate_fn`: {e}\")\n",
    "        return {\n",
    "            \"x\": {\n",
    "                \"x_cat\": torch.zeros((1, 2), dtype=torch.long),\n",
    "                \"x_cont\": torch.zeros((1, 5), dtype=torch.float32)\n",
    "            },\n",
    "            \"y\": torch.zeros((1, 1), dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "    \n",
    "# Définition des DataLoaders\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True, collate_fn=tft_collate_fn\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True, collate_fn=tft_collate_fn\n",
    ")\n",
    "\n",
    "for batch_idx, batch in enumerate(train_dataloader):\n",
    "    if not batch:\n",
    "        print(f\"❌ Batch {batch_idx} est VIDE dans `train_dataloader`.\")\n",
    "    elif isinstance(batch, dict):\n",
    "        print(f\"✅ Batch {batch_idx} est un dictionnaire contenant {list(batch.keys())}\")\n",
    "    else:\n",
    "        print(f\"❌ Type inconnu pour Batch {batch_idx}: {type(batch)}\")\n",
    "    \n",
    "    if batch_idx == 5:  # Vérifie seulement les 5 premiers batchs\n",
    "        break\n",
    "\n",
    "        \n",
    "# Callback d'Early Stopping pour éviter le surajustement\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=True, mode=\"min\")\n",
    "\n",
    "# Callback de Progression avec `tqdm`\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)  # Mettre à jour toutes les 10 itérations\n",
    "\n",
    "# Définition de l'entraîneur\n",
    "trainer = Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator=\"cpu\",  # ✅ Forcer l'utilisation du CPU\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[early_stop_callback, progress_bar]  # ✅ Ajout de la `Progress Bar`\n",
    ")\n",
    "\n",
    "for batch_idx, batch in enumerate(train_dataloader):\n",
    "    if not batch:\n",
    "        print(f\"❌ Batch {batch_idx} est VIDE dans `train_dataloader`.\")\n",
    "    elif isinstance(batch, dict):\n",
    "        print(f\"✅ Batch {batch_idx} est un dictionnaire contenant {list(batch.keys())} avec {batch['x']['x_cat'].shape[0]} échantillons\")\n",
    "    else:\n",
    "        print(f\"❌ Type inconnu pour Batch {batch_idx}: {type(batch)}\")\n",
    "    \n",
    "    if batch_idx == 5:  # Vérifie seulement les 5 premiers batchs\n",
    "        break\n",
    "\n",
    "        \n",
    "# Entraînement du modèle\n",
    "trainer.fit(tft_lightning, train_dataloader, test_dataloader)\n",
    "\n",
    "print(\"Entraînement terminé avec succès !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bbac84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af27ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c6dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0badc93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2963e5af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3524d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6096936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Sauvegarde du modèle après l'entraînement\n",
    "save_path = r\"..\\..\\Generated_Files\\TFT\\tft_model_checkpoint.ckpt\"\n",
    "trainer.save_checkpoint(save_path)\n",
    "\n",
    "print(f\"Modèle sauvegardé sous : {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e22b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb10e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a11db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6f2cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TFT)",
   "language": "python",
   "name": "tft_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
