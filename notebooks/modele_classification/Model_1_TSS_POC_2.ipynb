{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a55cb04",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center; font-family: Arial, sans-serif; color: #4CAF50;\">TSS - Temporal Similarity Search : POC complete DATASET WITH API - avec enregistrement fichier .json volumineux et fichier parquet petit (sur le local pas de API) mais trop lourd dans la recherche victorielle</h3>\n",
    "<ul style=\"font-family: Arial, sans-serif; font-size: 12pt; color: #333;\">\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b1d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kdbai-client"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9d0c534",
   "metadata": {},
   "source": [
    "Temporal Similarity Search (TSS) peut etre utilisé pour identifier des motifs temporels dans vos données de capteurs (TP2, DV_pressure, etc.) qui sont associés aux différentes valeurs de la colonne panne (0, 1, 2). Cela peut être particulièrement utile pour détecter des motifs qui précèdent ou correspondent à des pannes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4210acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Charger les données\n",
    "df = pd.read_csv(\"../Datasources/MetroPT3_imputed_final.csv\", delimiter=\",\", decimal=\".\", index_col=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d283704",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center; font-family: Arial, sans-serif; color: RED;\">################# DÉCLARATION / INITIALISATION #################</h3>\n",
    "<ul style=\"font-family: Arial, sans-serif; font-size: 12pt; color: #333;\">\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa8f748f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>panne</th>\n",
       "      <th>TP2</th>\n",
       "      <th>DV_pressure</th>\n",
       "      <th>Oil_temperature</th>\n",
       "      <th>Motor_current</th>\n",
       "      <th>Reservoirs</th>\n",
       "      <th>COMP</th>\n",
       "      <th>DV_eletric</th>\n",
       "      <th>Towers</th>\n",
       "      <th>LPS</th>\n",
       "      <th>Pressure_switch</th>\n",
       "      <th>Oil_level</th>\n",
       "      <th>Caudal_impulses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>53.600</td>\n",
       "      <td>0.04</td>\n",
       "      <td>9.358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01 00:00:10</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.675</td>\n",
       "      <td>0.04</td>\n",
       "      <td>9.348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  panne    TP2  DV_pressure  Oil_temperature  \\\n",
       "0 2020-02-01 00:00:00      0 -0.012       -0.024           53.600   \n",
       "1 2020-02-01 00:00:10      0 -0.014       -0.022           53.675   \n",
       "\n",
       "   Motor_current  Reservoirs  COMP  DV_eletric  Towers  LPS  Pressure_switch  \\\n",
       "0           0.04       9.358   1.0         0.0     1.0  0.0              1.0   \n",
       "1           0.04       9.348   1.0         0.0     1.0  0.0              1.0   \n",
       "\n",
       "   Oil_level  Caudal_impulses  \n",
       "0        1.0              1.0  \n",
       "1        1.0              1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convertir timestamp\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "#display(df.dtypes)\n",
    "\n",
    "continuous_features = [\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"]\n",
    "categorical_features = [\"COMP\", \"DV_eletric\", \"Towers\", \"LPS\", \"Pressure_switch\", \"Oil_level\", \"Caudal_impulses\"]\n",
    "\n",
    "# Conserver uniquement les colonnes continues, catégorielles et 'timestamp'\n",
    "columns_to_keep = [\"timestamp\", \"panne\"] + continuous_features + categorical_features\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ced8f6",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center; font-family: Arial, sans-serif; color: RED;\">#################### FIN DÉCLARATION #################</h3>\n",
    "<ul style=\"font-family: Arial, sans-serif; font-size: 12pt; color: #333;\">\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09843451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kdbai_client as kdbai\n",
    "session = kdbai.Session(endpoint=\"https://cloud.kdb.ai/instance/atr0v2owym\", api_key=\"a5b897a7b4-Av/lT//S3W++g8K11vVKfJo5rIj5gK492sbpts/1f+cr/5m5n5JluPcqcQR2gGiiQQ7SrCFAc7ma2RhT\")\n",
    "\n",
    "# create reference to default database\n",
    "db = session.database('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96951d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(db.tables)\n",
    "# Return: an empty array if no tables have been created []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2354c7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'train_sensors' supprimée avec succès.\n",
      "Table 'test_sensors' supprimée avec succès.\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "###### SUPPRIMER LES TABLES ######\n",
    "##################################\n",
    "# Accéder aux tables existantes\n",
    "train_table = db.table(\"train_sensors\")\n",
    "test_table = db.table(\"test_sensors\")\n",
    "\n",
    "# Supprimer mes 2 tables\n",
    "try:\n",
    "    train_table.drop()\n",
    "    test_table.drop()\n",
    "    print(\"Table 'train_sensors' supprimée avec succès.\")\n",
    "    print(\"Table 'test_sensors' supprimée avec succès.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la suppression de 'train_sensors' : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56de7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "################ Train : Panne2 & Panne3 & Panne4   ################\n",
    "################ Test  : Panne1           #########################\n",
    "###################################################################\n",
    "\n",
    "\n",
    "train_periods = [{'start': '2020-04-18 23:59:10', 'end': '2020-09-01 03:59:50'}]\n",
    "test_periods  = [{'start': '2020-02-01 00:00:00', 'end': '2020-04-18 23:59:00'}]\n",
    "\n",
    "train_df = pd.concat([\n",
    "    df[(df['timestamp'] >= pd.Timestamp(period['start'])) & \n",
    "       (df['timestamp'] <= pd.Timestamp(period['end']))]\n",
    "    for period in train_periods\n",
    "])\n",
    "\n",
    "# Filtrer les périodes pour le test\n",
    "test_df = pd.concat([\n",
    "    df[(df['timestamp'] >= pd.Timestamp(period['start'])) & \n",
    "       (df['timestamp'] <= pd.Timestamp(period['end']))]\n",
    "    for period in test_periods\n",
    "])\n",
    "\n",
    "print(f\"Entraînement : {len(train_df)} lignes\")\n",
    "print(f\"Test : {len(test_df)} lignes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c308e236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement : 9631 lignes\n",
      "Données d'entraînement (plage de temps) :\n",
      "2020-04-17 21:30:00 2020-04-19 00:15:00\n",
      "---------------------------\n",
      "Test : 271 lignes\n",
      "Données de test (plage de temps) :\n",
      "2020-07-15 14:00:00 2020-07-15 14:45:00\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "################ Train : Panne1   (1J ET DEMI)                                              #######\n",
    "################ Test  : Panne4  (15mn + 15mn + 15mn)     #########################################\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "train_periods = [{'start': '2020-04-17 21:30:00', 'end': '2020-04-19 00:15:00'}]\n",
    "test_periods  = [{'start': '2020-07-15 14:00:00', 'end': '2020-07-15 14:45:00'}]\n",
    "\n",
    "train_df = pd.concat([\n",
    "    df[(df['timestamp'] >= pd.Timestamp(period['start'])) & \n",
    "       (df['timestamp'] <= pd.Timestamp(period['end']))]\n",
    "    for period in train_periods\n",
    "])\n",
    "\n",
    "# Filtrer les périodes pour le test\n",
    "test_df = pd.concat([\n",
    "    df[(df['timestamp'] >= pd.Timestamp(period['start'])) & \n",
    "       (df['timestamp'] <= pd.Timestamp(period['end']))]\n",
    "    for period in test_periods\n",
    "])\n",
    "\n",
    "print(f\"Entrainement : {len(train_df)} lignes\")\n",
    "print(\"Données d'entraînement (plage de temps) :\")\n",
    "print(train_df['timestamp'].min(), train_df['timestamp'].max())\n",
    "print(\"---------------------------\")\n",
    "print(f\"Test : {len(test_df)} lignes\")\n",
    "print(\"Données de test (plage de temps) :\")\n",
    "print(test_df['timestamp'].min(), test_df['timestamp'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "337ed115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération des fenêtres pour l'entraînement...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 9532/9532 [00:08<00:00, 1099.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Génération des fenêtres pour le test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 172/172 [00:00<00:00, 1128.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fenêtres d'entraînement : 9532\n",
      "Fenêtres invalides d'entraînement : 0\n",
      "Fenêtres de test : 172\n",
      "Fenêtres invalides de test : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Paramètres des fenêtres temporelles\n",
    "window_size = 100  # Taille de la fenêtre\n",
    "step_size = 1      # Pas de glissement\n",
    "numeric_columns = [\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"]\n",
    "\n",
    "# Initialiser les compteurs pour les fenêtres invalides\n",
    "invalid_train_count = 0\n",
    "invalid_test_count = 0\n",
    "\n",
    "# Générer les fenêtres pour l'entraînement avec suivi de la progression\n",
    "train_windows = []\n",
    "print(\"Génération des fenêtres pour l'entraînement...\")\n",
    "for i in tqdm(range(0, len(train_df) - window_size + 1, step_size)):\n",
    "    # Extraire les données de la fenêtre\n",
    "    window_data = train_df.iloc[i:i + window_size][numeric_columns].values.flatten()\n",
    "    if len(window_data) == window_size * len(numeric_columns):  # Validation de la longueur\n",
    "        train_windows.append({\n",
    "            \"index\": i,\n",
    "            \"timestamp\": train_df.iloc[i][\"timestamp\"],\n",
    "            \"sensor_data\": window_data.tolist()\n",
    "        })\n",
    "    else:\n",
    "        invalid_train_count += 1  # Compter les fenêtres invalides\n",
    "\n",
    "# Générer les fenêtres pour le test avec suivi de la progression\n",
    "test_windows = []\n",
    "print(\"\\nGénération des fenêtres pour le test...\")\n",
    "for i in tqdm(range(0, len(test_df) - window_size + 1, step_size)):\n",
    "    # Extraire les données de la fenêtre\n",
    "    window_data = test_df.iloc[i:i + window_size][numeric_columns].values.flatten()\n",
    "    if len(window_data) == window_size * len(numeric_columns):  # Validation de la longueur\n",
    "        test_windows.append({\n",
    "            \"index\": i,\n",
    "            \"timestamp\": test_df.iloc[i][\"timestamp\"],\n",
    "            \"sensor_data\": window_data.tolist()\n",
    "        })\n",
    "    else:\n",
    "        invalid_test_count += 1  # Compter les fenêtres invalides\n",
    "\n",
    "# Afficher le nombre de fenêtres générées et invalides\n",
    "print(f\"\\nFenêtres d'entraînement : {len(train_windows)}\")\n",
    "print(f\"Fenêtres invalides d'entraînement : {invalid_train_count}\")\n",
    "print(f\"Fenêtres de test : {len(test_windows)}\")\n",
    "print(f\"Fenêtres invalides de test : {invalid_test_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00750e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les fenetres localement sur le C\n",
    "\n",
    "import json\n",
    "\n",
    "# Convertir les fenêtres pour rendre les Timestamps sérialisables\n",
    "def convert_windows(windows):\n",
    "    for window in windows:\n",
    "        window['timestamp'] = window['timestamp'].isoformat()  # Convertir en chaîne\n",
    "    return windows\n",
    "\n",
    "# Convertir et sauvegarder les fenêtres d'entraînement\n",
    "train_windows_serializable = convert_windows(train_windows)\n",
    "\n",
    "# Sauvegarder les fenêtres d'entraînement\n",
    "with open(\"train_windows.json\", \"w\") as train_file:\n",
    "    json.dump(train_windows, train_file)\n",
    "print(\"TSS_Fenêtres d'entraînement sauvegardées dans train_windows.json.\")\n",
    "\n",
    "# Convertir et sauvegarder les fenêtres de test\n",
    "test_windows_serializable = convert_windows(test_windows)\n",
    "# Sauvegarder les fenêtres de test\n",
    "with open(\"test_windows.json\", \"w\") as test_file:\n",
    "    json.dump(test_windows, test_file)\n",
    "print(\"TSS_Fenetres de test sauvegardées dans test_windows.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56ced09b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'train_sensors' supprimée avec succès.\n",
      "Table 'test_sensors' supprimée avec succès.\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "###### SUPPRIMER LES TABLES ######\n",
    "##################################\n",
    "# Accéder aux tables existantes\n",
    "train_table = db.table(\"train_sensors\")\n",
    "test_table = db.table(\"test_sensors\")\n",
    "\n",
    "# Supprimer mes 2 tables\n",
    "try:\n",
    "    train_table.drop()\n",
    "    test_table.drop()\n",
    "    print(\"Table 'train_sensors' supprimée avec succès.\")\n",
    "    print(\"Table 'test_sensors' supprimée avec succès.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la suppression de 'train_sensors' : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6207811c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'train_sensors' créée avec succès.\n",
      "Table 'test_sensors' créée avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Schéma pour les tables\n",
    "sensor_schema = [\n",
    "    {\"name\": \"index\", \"type\": \"int64\"},               # Identifiant unique\n",
    "    {\"name\": \"timestamp\", \"type\": \"datetime64[ns]\"}, # Timestamp\n",
    "    {\"name\": \"sensor_data\", \"type\": \"float64s\"}      # Données vectorielles\n",
    "                ]\n",
    "\n",
    "# Index pour la recherche vectorielle\n",
    "indexes = [\n",
    "    {\n",
    "        \"name\": \"flat_index\",\n",
    "        \"type\": \"flat\",\n",
    "        \"column\": \"sensor_data\",\n",
    "        \"params\": {\"metric\": \"L2\",\"dims\": 500}\n",
    "    }\n",
    "         ]\n",
    "\n",
    "# Créer les tables\n",
    "train_table = db.create_table(\"train_sensors\", schema=sensor_schema, indexes=indexes)\n",
    "test_table = db.create_table(\"test_sensors\", schema=sensor_schema, indexes=indexes)\n",
    "print(\"Table 'train_sensors' créée avec succès.\")\n",
    "print(\"Table 'test_sensors' créée avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40ce8c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion dans la table train_sensors... Total de batches : 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insertion dans train_sensors: 100%|████████████████████████████████████████████████████| 96/96 [00:46<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion dans la table test_sensors... Total de batches : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insertion dans test_sensors: 100%|███████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion des données terminée.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from kdbai_client import KDBAIException\n",
    "\n",
    "# Fonction d'insertion des données\n",
    "def insert_data(table, data_windows, batch_size=100):\n",
    "    \"\"\"\n",
    "    Insère les données dans une table KDB.AI par lots avec une barre de progression.\n",
    "    \"\"\"\n",
    "    total_batches = -(-len(data_windows) // batch_size)  # Calculer le nombre total de batches\n",
    "    print(f\"Insertion dans la table {table.name}... Total de batches : {total_batches}\")\n",
    "    \n",
    "    with tqdm(total=total_batches, desc=f\"Insertion dans {table.name}\") as pbar:\n",
    "        for batch_index, i in enumerate(range(0, len(data_windows), batch_size), start=1):\n",
    "            batch = data_windows[i:i + batch_size]\n",
    "            try:\n",
    "                table.insert(batch)\n",
    "                pbar.update(1)\n",
    "            except KDBAIException as e:\n",
    "                pbar.set_postfix({\"Erreur\": \"Oui\"})\n",
    "                print(f\"Erreur lors de l'insertion du batch {batch_index}/{total_batches}: {e}\")\n",
    "                for record in batch:\n",
    "                    try:\n",
    "                        table.insert([record])  # Tentative d'insertion individuelle pour débogage\n",
    "                    except KDBAIException as single_error:\n",
    "                        print(f\"Erreur sur l'enregistrement {record['index']}: {single_error}\")\n",
    "\n",
    "# Insertion des données d'entraînement\n",
    "insert_data(train_table, train_windows)\n",
    "\n",
    "# Insertion des données de test\n",
    "insert_data(test_table, test_windows)\n",
    "\n",
    "print(\"Insertion des données terminée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8c9c04e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement : 9631 lignes\n",
      "Nombre de lignes : 0    9532\n",
      "Name: row_count, dtype: int64\n",
      "Timestamp minimum : 0   2020-04-17 21:30:00\n",
      "Name: min_timestamp, dtype: datetime64[ns]\n",
      "Timestamp maximum : 0   2020-04-18 23:58:30\n",
      "Name: max_timestamp, dtype: datetime64[ns]\n",
      "----------------------------\n",
      "Test : 271 lignes\n",
      "Nombre de lignes : 0    172\n",
      "Name: row_count, dtype: int64\n",
      "Timestamp minimum : 0   2020-07-15 14:00:00\n",
      "Name: min_timestamp, dtype: datetime64[ns]\n",
      "Timestamp maximum : 0   2020-07-15 14:28:30\n",
      "Name: max_timestamp, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Compte le nombre de lignes en utilisant la colonne 'index'\n",
    "print(f\"Entrainement : {len(train_df)} lignes\")\n",
    "\n",
    "aggs = {\n",
    "    \"row_count\": [\"count\", \"index\"],\n",
    "    \"min_timestamp\": [\"min\", \"timestamp\"],\n",
    "    \"max_timestamp\": [\"max\", \"timestamp\"],\n",
    "}\n",
    "\n",
    "query_result = train_table.query(aggs=aggs)\n",
    "print(f\"Nombre de lignes : {query_result['row_count']}\")\n",
    "print(f\"Timestamp minimum : {query_result['min_timestamp']}\")\n",
    "print(f\"Timestamp maximum : {query_result['max_timestamp']}\")\n",
    "print(\"----------------------------\")\n",
    "print(f\"Test : {len(test_df)} lignes\")\n",
    "query_result = test_table.query(aggs=aggs)\n",
    "print(f\"Nombre de lignes : {query_result['row_count']}\")\n",
    "print(f\"Timestamp minimum : {query_result['min_timestamp']}\")\n",
    "print(f\"Timestamp maximum : {query_result['max_timestamp']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f82a3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Résultats de recherche vectorielle :\n",
      "Index d'entraînement : 6241, Distance : 3817.813720703125\n",
      "Timestamp correspondant : 2020-04-18 14:50:10\n",
      "Motif similaire (extrait des données capteurs) : [ 9.02    2.022  77.025   5.6875  8.882 ] ...\n",
      "Index d'entraînement : 6240, Distance : 3823.2158203125\n",
      "Timestamp correspondant : 2020-04-18 14:50:00\n",
      "Motif similaire (extrait des données capteurs) : [ 9.02    2.022  77.075   5.7425  8.876 ] ...\n",
      "Index d'entraînement : 6239, Distance : 3830.301025390625\n",
      "Timestamp correspondant : 2020-04-18 14:49:50\n",
      "Motif similaire (extrait des données capteurs) : [ 8.662   1.916  77.025   5.7325  8.884 ] ...\n",
      "Index d'entraînement : 6242, Distance : 3843.76953125\n",
      "Timestamp correspondant : 2020-04-18 14:50:20\n",
      "Motif similaire (extrait des données capteurs) : [ 9.02   2.024 76.9    5.685  8.886] ...\n",
      "Index d'entraînement : 6238, Distance : 3847.65771484375\n",
      "Timestamp correspondant : 2020-04-18 14:49:40\n",
      "Motif similaire (extrait des données capteurs) : [ 7.532   1.588  76.875   5.4775  8.9   ] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\AppData\\Local\\Temp\\ipykernel_7596\\409578788.py:48: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Exemple de prédiction avec une fenêtre de test\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"numpy\")\n",
    "\n",
    "\n",
    "# Sélectionner un vecteur de requête (par exemple, la première fenêtre de test)\n",
    "query_vector = test_windows[0][\"sensor_data\"]\n",
    "\n",
    "# Effectuer une recherche vectorielle dans la table d'entraînement\n",
    "results = train_table.search(\n",
    "    vectors={\"flat_index\": [query_vector]},\n",
    "    n=5,  # Trouver les 5 motifs les plus similaires\n",
    ")\n",
    "\n",
    "# Afficher les résultats de la recherche\n",
    "print(\"\\nRésultats de recherche vectorielle :\")\n",
    "for i, row in results[0].iterrows():\n",
    "    print(f\"Index d'entraînement : {row['index']}, Distance : {row['__nn_distance']}\")\n",
    "    print(f\"Timestamp correspondant : {row['timestamp']}\")\n",
    "    print(f\"Motif similaire (extrait des données capteurs) : {row['sensor_data'][:5]} ...\")\n",
    "\n",
    "# Extraire les indices similaires pour les visualiser\n",
    "similar_indices = results[0]['index']\n",
    "\n",
    "# Visualiser le motif de test et les motifs similaires\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Tracer le vecteur de test\n",
    "plt.plot(query_vector, marker=\"o\", linestyle=\"-\", label=\"Motif de Test\", color=\"blue\")\n",
    "\n",
    "# Parcourir les indices similaires\n",
    "for idx in similar_indices:\n",
    "    # Requête pour récupérer les vecteurs similaires\n",
    "    result_row = results[0][results[0]['index'] == idx]\n",
    "    similar_vector = result_row['sensor_data'].iloc[0]\n",
    "    \n",
    "    # Tracer les vecteurs similaires\n",
    "    plt.plot(similar_vector, marker=\"o\", linestyle=\"--\", alpha=0.7, label=f\"Similaire {idx}\")\n",
    "\n",
    "# Ajouter des étiquettes et une légende\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Valeurs des Capteurs\")\n",
    "plt.title(\"Comparaison des Motifs : Test vs Similaires\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b73d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be13279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9dbd61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e8ecdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c894af",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batches = len(train_windows) // batch_size + (len(train_windows) % batch_size > 0)\n",
    "print(f\"Nombre de batches attendu : {total_batches}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = train_df[train_df.duplicated()]\n",
    "print(f\"Lignes dupliquées dans train_df : {len(duplicate_rows)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f332bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = train_table.query(select=[\"timestamp\"])\n",
    "db_min_timestamp = query_result[\"timestamp\"].min()\n",
    "db_max_timestamp = query_result[\"timestamp\"].max()\n",
    "print(f\"Plage temporelle dans la base : {db_min_timestamp} à {db_max_timestamp}\")\n",
    "print(f\"Plage temporelle locale : {train_df['timestamp'].min()} à {train_df['timestamp'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a126b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eea561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b339734",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center; font-family: Arial, sans-serif; color: BLUE;\">################# QUELQUES VALIDATIONS #################</h3>\n",
    "<ul style=\"font-family: Arial, sans-serif; font-size: 12pt; color: #333;\">\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc17416",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"Premiere fenetre train:\\n{train_windows[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = {\n",
    "    \"row_count\": [\"count\", \"index\"],\n",
    "    \"min_timestamp\": [\"min\", \"timestamp\"],\n",
    "    \"max_timestamp\": [\"max\", \"timestamp\"],\n",
    "}\n",
    "\n",
    "query_result = train_table.query(aggs=aggs)\n",
    "print(f\"Nombre de lignes : {query_result['row_count']}\")\n",
    "print(f\"Timestamp minimum : {query_result['min_timestamp']}\")\n",
    "print(f\"Timestamp maximum : {query_result['max_timestamp']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer les timestamps entre train_df et KDB.ai\n",
    "db_timestamps = pd.date_range(start=\"2020-04-17 21:30:00\", end=\"2020-04-18 23:58:30\", freq=\"10s\")\n",
    "missing_timestamps = train_df[~train_df[\"timestamp\"].isin(db_timestamps)]\n",
    "\n",
    "print(f\"Lignes manquantes dans la base : {len(missing_timestamps)}\")\n",
    "print(missing_timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3621722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les lignes manquantes pour l'insertion\n",
    "missing_rows = []\n",
    "for row in missing_timestamps.itertuples(index=True, name=\"Row\"):\n",
    "    missing_rows.append({\n",
    "        \"index\": row.Index,  # Utiliser l'index fourni par itertuples\n",
    "        \"timestamp\": row.timestamp,\n",
    "        \"sensor_data\": list(row[2:])  # Inclure les colonnes numériques sous forme de liste\n",
    "    })\n",
    "\n",
    "# Insérer les données manquantes dans la table train_sensors\n",
    "batch_size = 10  # Taille du batch pour l'insertion\n",
    "print(f\"Réinsertion des {len(missing_rows)} lignes manquantes...\")\n",
    "\n",
    "for i in range(0, len(missing_rows), batch_size):\n",
    "    batch = missing_rows[i:i + batch_size]\n",
    "    try:\n",
    "        train_table.insert(batch)\n",
    "        print(f\"Batch {i // batch_size + 1}/{-(-len(missing_rows) // batch_size)} inséré avec succès.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'insertion du batch {i // batch_size + 1} : {e}\")\n",
    "\n",
    "print(\"Réinsertion des données manquantes terminée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a0fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifiez les colonnes utilisées pour la création de sensor_data\n",
    "numeric_columns = [\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"]  # Exemple\n",
    "print(\"Colonnes utilisées pour sensor_data :\", numeric_columns)\n",
    "\n",
    "# Préparer les lignes manquantes pour l'insertion\n",
    "missing_rows = []\n",
    "for row in missing_timestamps.itertuples(index=True, name=\"Row\"):\n",
    "    # Vérifiez les données avant de les ajouter\n",
    "    try:\n",
    "        sensor_data = [getattr(row, col) for col in numeric_columns]  # Extraire les colonnes nécessaires\n",
    "        missing_rows.append({\n",
    "            \"index\": row.Index,  # Utiliser l'index fourni par itertuples\n",
    "            \"timestamp\": row.timestamp,\n",
    "            \"sensor_data\": sensor_data  # Liste de données numériques\n",
    "        })\n",
    "    except AttributeError as e:\n",
    "        print(f\"Erreur lors de la préparation des données pour l'index {row.Index} : {e}\")\n",
    "\n",
    "# Réinsertion dans la base\n",
    "batch_size = 10\n",
    "print(f\"Réinsertion des {len(missing_rows)} lignes manquantes...\")\n",
    "\n",
    "for i in range(0, len(missing_rows), batch_size):\n",
    "    batch = missing_rows[i:i + batch_size]\n",
    "    try:\n",
    "        train_table.insert(batch)\n",
    "        print(f\"Batch {i // batch_size + 1}/{-(-len(missing_rows) // batch_size)} inséré avec succès.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'insertion du batch {i // batch_size + 1} : {e}\")\n",
    "\n",
    "print(\"Réinsertion des données manquantes terminée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b5a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification des dimensions de chaque vecteur avant l'insertion\n",
    "expected_length = 500  # Longueur attendue des vecteurs\n",
    "\n",
    "invalid_vectors = []\n",
    "for row in missing_rows:\n",
    "    if len(row[\"sensor_data\"]) != expected_length:\n",
    "        invalid_vectors.append(row)\n",
    "\n",
    "# Si des vecteurs invalides sont trouvés, les afficher\n",
    "if invalid_vectors:\n",
    "    print(f\"Vecteurs invalides détectés : {len(invalid_vectors)}\")\n",
    "    for idx, invalid_row in enumerate(invalid_vectors[:5]):  # Afficher les 5 premiers vecteurs invalides\n",
    "        print(f\"Index : {invalid_row['index']}, Longueur : {len(invalid_row['sensor_data'])}\")\n",
    "else:\n",
    "    print(\"Tous les vecteurs ont la bonne dimension.\")\n",
    "\n",
    "# Réinsertion uniquement des vecteurs valides\n",
    "valid_rows = [row for row in missing_rows if len(row[\"sensor_data\"]) == expected_length]\n",
    "\n",
    "print(f\"Réinsertion des {len(valid_rows)} lignes valides...\")\n",
    "for i in range(0, len(valid_rows), batch_size):\n",
    "    batch = valid_rows[i:i + batch_size]\n",
    "    try:\n",
    "        train_table.insert(batch)\n",
    "        print(f\"Batch {i // batch_size + 1}/{-(-len(valid_rows) // batch_size)} inséré avec succès.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'insertion du batch {i // batch_size + 1} : {e}\")\n",
    "\n",
    "print(\"Réinsertion des données valides terminée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4eb458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taille réelle de la première fenêtre\n",
    "print(f\"Taille des données dans la première fenêtre d'entraînement : {len(train_windows[0]['sensor_data'])}\")\n",
    "print(f\"Taille des données dans la première fenêtre de test : {len(test_windows[0]['sensor_data'])}\")\n",
    "\n",
    "# Cela correspond à window_size (100) × nombre de colonnes (numeric_columns, soit 5).\n",
    "\n",
    "print('--------------------------------')\n",
    "# Vérifier la taille des fenêtres générées\n",
    "for i in range(5):  # Tester sur les 5 premières fenêtres\n",
    "    actual_window = train_df.iloc[i:i + window_size][numeric_columns]\n",
    "    print(f\"Fenêtre {i} - Taille réelle : {len(actual_window)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0d2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser des compteurs pour détecter les erreurs\n",
    "invalid_index_count = 0\n",
    "invalid_timestamp_count = 0\n",
    "invalid_sensor_data_count = 0\n",
    "\n",
    "# Parcourir toutes les fenêtres pour vérifier les types et formats\n",
    "for i, window in enumerate(train_windows):\n",
    "    # Vérifier l'index\n",
    "    if not isinstance(window['index'], int):\n",
    "        print(f\"Fenêtre {i} : 'index' non valide ({type(window['index'])})\")\n",
    "        invalid_index_count += 1\n",
    "    \n",
    "    # Vérifier le timestamp\n",
    "    try:\n",
    "        pd.Timestamp(window['timestamp'])  # Vérifie si le timestamp est convertible\n",
    "    except Exception as e:\n",
    "        print(f\"Fenêtre {i} : 'timestamp' non valide ({window['timestamp']})\")\n",
    "        invalid_timestamp_count += 1\n",
    "    \n",
    "    # Vérifier sensor_data\n",
    "    if not isinstance(window['sensor_data'], list) or len(window['sensor_data']) != 500:\n",
    "        print(f\"Fenêtre {i} : 'sensor_data' non valide (Longueur : {len(window['sensor_data'])})\")\n",
    "        invalid_sensor_data_count += 1\n",
    "    elif not all(isinstance(value, float) for value in window['sensor_data']):\n",
    "        print(f\"Fenêtre {i} : 'sensor_data' contient des valeurs non flottantes.\")\n",
    "        invalid_sensor_data_count += 1\n",
    "\n",
    "# Résumé des erreurs détectées\n",
    "print(f\"Erreurs dans 'index' : {invalid_index_count}\")\n",
    "print(f\"Erreurs dans 'timestamp' : {invalid_timestamp_count}\")\n",
    "print(f\"Erreurs dans 'sensor_data' : {invalid_sensor_data_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cde4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester l'insertion avec un petit lot\n",
    "\n",
    "# Schéma pour les tables\n",
    "sensor_schema = [\n",
    "    {\"name\": \"index\", \"type\": \"int64\"},               # Identifiant unique\n",
    "    {\"name\": \"timestamp\", \"type\": \"datetime64[ns]\"}, # Timestamp\n",
    "    {\"name\": \"sensor_data\", \"type\": \"float64s\"}      # Données vectorielles\n",
    "]\n",
    "\n",
    "# Index pour la recherche vectorielle\n",
    "indexes = [\n",
    "    {\n",
    "        \"name\": \"flat_index\",\n",
    "        \"type\": \"flat\",\n",
    "        \"column\": \"sensor_data\",\n",
    "        \"params\": {\"metric\": \"L2\",\"dims\": 500}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Créer les tables\n",
    "train_table = db.create_table(\"train_sensors\", schema=sensor_schema, indexes=indexes)\n",
    "test_table = db.create_table(\"test_sensors\", schema=sensor_schema, indexes=indexes)\n",
    "\n",
    "\n",
    "single_window = [train_windows[0]]  # Utiliser uniquement la première fenêtre\n",
    "try:\n",
    "    train_table.insert(single_window)\n",
    "    print(\"Insertion réussie pour une seule fenêtre.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de l'insertion d'une seule fenêtre : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    datetime.fromisoformat(single_window[0]['timestamp'])\n",
    "    print(\"Le format du timestamp est correct.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Problème avec le format du timestamp : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6cfde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in single_window[0]['sensor_data']:\n",
    "    if not isinstance(value, float):\n",
    "        print(f\"Problème détecté : {value} de type {type(value)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3027d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(single_window[0]['sensor_data']) != 500:\n",
    "    print(\"La longueur de sensor_data n'est pas correcte.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99a1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Schéma de la table :\")\n",
    "print(train_table.schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09306af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for window in train_windows:\n",
    "    window['timestamp'] = datetime.fromisoformat(window['timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e081c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table.query(limit=5)  # Affiche les 5 premières lignes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d40933",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_row_count = test_table.query(aggs=aggs)\n",
    "print(f\"Lignes stockées dans la table de test : {test_row_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582efcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le contenu du lot envoyé pour inspection\n",
    "print(\"Contenu du lot de test :\")\n",
    "for i, window in enumerate(test_batch):\n",
    "    print(f\"Fenêtre {i}: {window}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35129c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification approfondie des valeurs\n",
    "for i, window in enumerate(test_batch):\n",
    "    if not all(isinstance(v, float) and not (np.isnan(v) or np.isinf(v)) for v in window['sensor_data']):\n",
    "        print(f\"Fenêtre {i} contient des valeurs invalides.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284723a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer les valeurs invalides par une valeur par défaut (ex. : 0.0)\n",
    "for window in train_windows:\n",
    "    window['sensor_data'] = [\n",
    "        0.0 if (np.isnan(v) or np.isinf(v)) else v\n",
    "        for v in window['sensor_data']\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab304785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier la structure des 5 premières fenêtres\n",
    "for window in train_windows[:5]:\n",
    "    print(f\"Index : {window['index']}\")\n",
    "    print(f\"Timestamp : {window['timestamp']}\")\n",
    "    print(f\"Longueur de sensor_data : {len(window['sensor_data'])}\")\n",
    "    print(f\"Exemple de données : {window['sensor_data'][:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5e6b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification des longueurs des fenêtres\n",
    "for i, window in enumerate(train_windows):\n",
    "    if len(window['sensor_data']) != window_size * len(numeric_columns):\n",
    "        print(f\"Fenêtre {i} a une taille incorrecte : {len(window['sensor_data'])}\")\n",
    "print(\"Validation de la longueur des fenêtres terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la continuité temporelle\n",
    "for i, window in enumerate(train_windows):\n",
    "    timestamps = train_df.iloc[window['index']:window['index'] + window_size]['timestamp']\n",
    "    time_diffs = timestamps.diff().dt.total_seconds().dropna()\n",
    "    if not all(time_diffs == 10):  # Vérifie si tous les gaps sont de 10 secondes\n",
    "        print(f\"Fenêtre {i} a des timestamps non consécutifs.\")\n",
    "print(\"Validation de la continuité temporelle terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d5a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple : Vérifier la réponse brute\n",
    "response = train_table.insert(train_windows[:5])\n",
    "print(\"Réponse brute :\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1bc360",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea27738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requête pour compter les lignes dans une table\n",
    "train_row_count = db.query(\"SELECT COUNT(*) AS row_count FROM train_sensors\").iloc[0]['row_count']\n",
    "print(f\"Lignes stockées dans la table d'entraînement : {train_row_count}\")\n",
    "\n",
    "test_row_count = db.query(\"SELECT COUNT(*) AS row_count FROM test_sensors\").iloc[0]['row_count']\n",
    "print(f\"Lignes stockées dans la table de test : {test_row_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b880403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher toutes les méthodes et attributs de l'objet db\n",
    "print(dir(db.tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher toutes les méthodes et attributs de l'objet train_table\n",
    "print(dir(train_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef12454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les détails sur la méthode query\n",
    "help(train_table.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b4cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir l'agrégation pour compter les lignes\n",
    "aggs = {'row_count': ['count', 'index']}  # Compte le nombre de lignes en utilisant la colonne 'index'\n",
    "\n",
    "# Effectuer la requête pour compter les lignes\n",
    "train_row_count = train_table.query(aggs=aggs)\n",
    "print(f\"Lignes stockées dans la table d'entraînement : {train_row_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e0916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametres des fenetres temporelles\n",
    "window_size = 100  # Taille de la fenetre\n",
    "step_size = 1      # Pas de glissement\n",
    "numeric_columns = [\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"]\n",
    "\n",
    "# Générer les fenetres pour l'entrainement\n",
    "train_windows = [\n",
    "    {\n",
    "        \"index\": i,\n",
    "        \"timestamp\": train_df.iloc[i][\"timestamp\"],\n",
    "        \"sensor_data\": train_df.iloc[i:i + window_size][numeric_columns].values.flatten().tolist()\n",
    "    }\n",
    "    for i in range(0, len(train_df) - window_size + 1, step_size)\n",
    "]\n",
    "\n",
    "# Générer les fenetres pour le test\n",
    "test_windows = [\n",
    "    {\n",
    "        \"index\": i,\n",
    "        \"timestamp\": test_df.iloc[i][\"timestamp\"],\n",
    "        \"sensor_data\": test_df.iloc[i:i + window_size][numeric_columns].values.flatten().tolist()\n",
    "    }\n",
    "    for i in range(0, len(test_df) - window_size + 1, step_size)\n",
    "]\n",
    "\n",
    "print(f\"Fenêtres d'entraînement : {len(train_windows)}\")\n",
    "print(f\"Fenêtres de test : {len(test_windows)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f9227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "numeric_columns = [\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"]\n",
    "\n",
    "# Construire les vecteurs pour chaque fenetre (numeric_columns)\n",
    "window_vectors = np.array([\n",
    "    window[numeric_columns].values.flatten() for window in windows\n",
    "])\n",
    "\n",
    "# Appliquer PCA pour réduire la dimensionnalité\n",
    "pca = PCA(n_components=8)  # Réduire a 8 dimensions\n",
    "compressed_vectors = pca.fit_transform(window_vectors)\n",
    "\n",
    "print(f\"Dimensions des vecteurs compressés : {compressed_vectors.shape}\")\n",
    "print(f\"Vecteur compressé pour la première fenêtre : {compressed_vectors[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
